{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0045cd26",
   "metadata": {},
   "source": [
    "# EDA - 결측치/이상치 탐지 및 처리(심화)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdccd89",
   "metadata": {},
   "source": [
    "## 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b2e7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# 온라인 소매 데이터 생성 (컬럼명 소문자 버전)\n",
    "np.random.seed(42)\n",
    "n_customers = 1000\n",
    "\n",
    "def create_realistic_ecommerce_data(n=1000):\n",
    "    \"\"\"실제와 유사한 전자상거래 데이터 생성 (소문자 컬럼명)\"\"\"\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    # 고객 기본 정보\n",
    "    data['customer_id'] = range(1, n+1)\n",
    "    data['age'] = np.random.normal(35, 12, n).clip(18, 80).astype(int)\n",
    "    data['gender'] = np.random.choice(['M', 'F'], n, p=[0.45, 0.55])\n",
    "    data['city'] = np.random.choice(['Seoul', 'Busan', 'Daegu', 'Incheon', 'Gwangju'], \n",
    "                                   n, p=[0.4, 0.2, 0.15, 0.15, 0.1])\n",
    "    \n",
    "    # 구매 행동 데이터\n",
    "    data['total_purchases'] = np.random.poisson(8, n) + 1\n",
    "    data['avg_order_value'] = np.random.lognormal(4.5, 0.8, n).round(2)\n",
    "    data['days_since_last_purchase'] = np.random.exponential(30, n).astype(int)\n",
    "    \n",
    "    # 만족도 및 충성도\n",
    "    data['satisfaction_score'] = np.random.normal(3.8, 1.2, n).clip(1, 5).round(1)\n",
    "    data['loyalty_points'] = (data['total_purchases'] * data['avg_order_value'] * 0.1 + \n",
    "                             np.random.normal(0, 100, n)).clip(0, None).round(0)\n",
    "    \n",
    "    # 카테고리별 구매 금액\n",
    "    categories = ['electronics', 'clothing', 'books', 'home', 'sports']\n",
    "    for cat in categories:\n",
    "        # 일부 고객은 특정 카테고리에서 구매하지 않음\n",
    "        values = np.random.lognormal(3, 1, n)\n",
    "        # 30% 확률로 해당 카테고리 구매 안 함 (0으로 설정)\n",
    "        mask = np.random.random(n) < 0.3\n",
    "        values[mask] = 0\n",
    "        data[f'{cat}_spending'] = values.round(2)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # 의도적 결측값 생성 (실제 상황 모방)\n",
    "    \n",
    "    # 1. MCAR(Missing Completely at Random): 완전 무작위 결측 (시스템 오류)\n",
    "    missing_indices = np.random.choice(df.index, size=int(0.05 * len(df)), replace=False)\n",
    "    df.loc[missing_indices, 'satisfaction_score'] = np.nan\n",
    "    \n",
    "    # 2. MAR(Missing at Random): 조건부 결측 (나이가 높을수록 만족도 응답 거부율 증가)\n",
    "    elderly_mask = df['age'] > 50\n",
    "    elderly_missing = np.random.random(elderly_mask.sum()) < 0.15  \n",
    "    elderly_indices = df[elderly_mask].index[elderly_missing]\n",
    "    df.loc[elderly_indices, 'satisfaction_score'] = np.nan\n",
    "    \n",
    "    # 3. MNAR(Missing Not at Random): 비무작위 결측 - 결측 자체가 의미 (높은 소득자들이 개인정보 비공개)\n",
    "    high_spenders = df['avg_order_value'] > df['avg_order_value'].quantile(0.8)\n",
    "    high_spender_missing = np.random.random(high_spenders.sum()) < 0.25\n",
    "    high_spender_indices = df[high_spenders].index[high_spender_missing]\n",
    "    df.loc[high_spender_indices, 'age'] = np.nan\n",
    "    \n",
    "    # 도시 정보 일부 결측 (배송지 미입력)\n",
    "    city_missing = np.random.choice(df.index, size=int(0.08 * len(df)), replace=False)\n",
    "    df.loc[city_missing, 'city'] = np.nan\n",
    "    \n",
    "    # 의도적 이상값 생성\n",
    "    \n",
    "    # 1. 데이터 입력 오류 (나이 999살)\n",
    "    error_indices = np.random.choice(df.index, size=3, replace=False)\n",
    "    df.loc[error_indices, 'age'] = 999\n",
    "    \n",
    "    # 2. 비즈니스 이상값 (VIP 고객의 극도로 높은 구매액) Extreme but Valid Outliers\n",
    "    vip_indices = np.random.choice(df.index, size=5, replace=False)\n",
    "    df.loc[vip_indices, 'avg_order_value'] *= 20\n",
    "    df.loc[vip_indices, 'loyalty_points'] *= 10\n",
    "    \n",
    "    # 3. 시스템 버그로 인한 음수값\n",
    "    bug_indices = np.random.choice(df.index, size=2, replace=False) \n",
    "    df.loc[bug_indices, 'days_since_last_purchase'] = -1\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 데이터 생성\n",
    "ecommerce = create_realistic_ecommerce_data(1000)\n",
    "\n",
    "print(\"=== 온라인 소매 데이터 개요 ===\")\n",
    "print(f\"데이터 크기: {ecommerce.shape}\")\n",
    "print(\"\\n데이터 샘플:\")\n",
    "display(ecommerce.head(10))\n",
    "\n",
    "print(f\"\\n기본 정보:\")\n",
    "print(ecommerce.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f691ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전반적인 상태 점검 - da_utils/profile.py 모듈(파일) 안의 get_data_profile 함수를 가져옴\n",
    "from da_utils.profile import get_data_profile # 바로 get_data_profile 함수를 꺼냈음\n",
    "# from da_utils import profile                # profile 모듈 전체를 꺼내서 실제로 사용할 때는 profile.get_data_profile 로 사용해야 함\n",
    "\n",
    "data_report = get_data_profile(ecommerce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f12a9a",
   "metadata": {},
   "source": [
    "## 결측치 패턴 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059bfdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 패턴 분석\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 설정 (선택사항)\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def analyze_missing_patterns(df: pd.DataFrame):\n",
    "    \"\"\"결측값 패턴 종합 분석\"\"\"\n",
    "    \n",
    "    print('=== 결측값 패턴 분석 ===')\n",
    "    missing_info = df.isna().sum()\n",
    "    missing_pct = (missing_info / len(df)) * 100\n",
    "    missing_summary = pd.DataFrame({\n",
    "        '결측수': missing_info,\n",
    "        '결측률(%)': missing_pct.round(2),\n",
    "    })\n",
    "    missing_summary = missing_summary[missing_summary['결측수'] > 0].sort_values('결측수', ascending=False)\n",
    "    print('변수별 결측 현황')\n",
    "    display(missing_summary)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15,10))\n",
    "    a1, a2, a3, a4 = axes[0,0], axes[0,1], axes[1,0], axes[1,1]\n",
    "    \n",
    "    # 1. 결측값 히트맵\n",
    "    sns.heatmap(df.isna(), yticklabels=False, cbar=True, cmap='viridis', ax=a1)\n",
    "    a1.set_title('결측값 패턴 히트맵')\n",
    "    \n",
    "    # 2. 변수별 결측률 바 차트\n",
    "    if len(missing_summary) > 0:  # >0은 생략 가능(내용이 있다면)\n",
    "        missing_summary['결측률(%)'].plot(kind='bar', color='coral', ax=a2)\n",
    "        a2.set_title('변수별 결측률')    \n",
    "        a2.set_ylabel('결측률(%)')\n",
    "        a2.tick_params(axis='x', rotation=0)\n",
    "    \n",
    "    # 3. 결측값 조합 패턴 - 결측이 동시에 발생하는 변수 파악 후 유의미하게 많으면 연관을 생각할 수 있음 -> 4번에서 그룹별로 처리 가능\n",
    "    '''\n",
    "    df.isna().any()                           -> 컬럼에 결측값이 있으면 True, 없으면 False\n",
    "    df.columns[df.isna().any()]               -> 결측값이 있는 컬럼명을 추출\n",
    "    df[df.columns[df.isna().any()]]           -> 결측값이 있는 컬럼의 전체값을 추출함\n",
    "    df[df.columns[df.isna().any()]].isna()    -> 결측값이라면 True로 설정함\n",
    "    결측값이 있는 age, city, satisfaction_score 간에 어떤 조합이 가장 많은지 파악\n",
    "    '''\n",
    "    missing_pattern = df[df.columns[df.isna().any()]].isna()\n",
    "    if len(missing_pattern):\n",
    "        pattern_counts = missing_pattern.value_counts().head(10)\n",
    "        pattern_counts.plot(kind='bar', color='lightblue', ax=a3)\n",
    "        a3.set_title('결측 패턴 조합(상위 10개)')\n",
    "        a3.set_ylabel('빈도')\n",
    "        a3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "\n",
    "    # 4. 결측 변수별 결측 여부(0/1)와 다른 수치형 변수 간 상관관계 히트맵 시각화\n",
    "    numeric_cols = df.select_dtypes(include='number').columns.tolist()\n",
    "    missing_cols = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "    if len(numeric_cols) > 0 and len(missing_cols) > 0:\n",
    "        # 결측값을 0/1로 변환한 DataFrame 생성\n",
    "        missing_binary = df[missing_cols].isna().astype(int)\n",
    "        missing_binary.columns = [f'{col}_missing' for col in missing_binary.columns]\n",
    "        \n",
    "        # 수치형 변수와 결측 패턴 변수 결합\n",
    "        corr_data = pd.concat([df[numeric_cols], missing_binary], axis=1)\n",
    "        \n",
    "        # 상관계수 계산\n",
    "        correlation_matrix = corr_data.corr()\n",
    "        \n",
    "        # 결측 패턴 변수와 수치형 변수 간의 상관관계만 추출\n",
    "        missing_numeric_corr = correlation_matrix.loc[\n",
    "            missing_binary.columns, \n",
    "            numeric_cols\n",
    "        ]\n",
    "        \n",
    "        # 상관관계가 있는 경우에만 히트맵 그리기\n",
    "        if missing_numeric_corr.shape[0] > 0 and missing_numeric_corr.shape[1] > 0:\n",
    "            sns.heatmap(\n",
    "                    missing_numeric_corr, \n",
    "                    annot=True, \n",
    "                    cmap='coolwarm', \n",
    "                    center=0,\n",
    "                    fmt='.2f',\n",
    "                    ax=a4,\n",
    "                    cbar_kws={'label': '상관계수'},\n",
    "                )\n",
    "            a4.set_title('결측 패턴과 수치형 변수 간 상관관계')\n",
    "            a4.set_xlabel('수치형 변수')\n",
    "            a4.set_ylabel('결측 패턴')\n",
    "        else:\n",
    "            a4.text(0.5, 0.5, '분석할 상관관계 없음', ha='center', va='center')\n",
    "            a4.axis('off')\n",
    "    else:\n",
    "        a4.text(0.5, 0.5, '수치형 변수 또는\\n결측값이 없음', ha='center', va='center')\n",
    "        a4.axis('off')\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "analyze_missing_patterns(ecommerce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b022406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 모듈에서 불러오기\n",
    "\n",
    "from da_utils.patterns import analyze_missing_patterns\n",
    "analyze_missing_patterns(ecommerce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e098e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측 메커니즘 진단\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "print('=== 결측 메커니즘 진단 ===')\n",
    "\n",
    "# MAR(조건부) 패턴\n",
    "# 가설: 나이 결측과 구매액 간 관계\n",
    "if ecommerce['age'].isna().sum():\n",
    "    print('\\n1. 나이(age) 결측 메커니즘 분석')\n",
    "\n",
    "    # 구매액 분위별 나이 결측률\n",
    "    df_temp = ecommerce.copy()\n",
    "    df_temp['spending_quertile'] = pd.qcut(df_temp['avg_order_value'].dropna(), q=4, labels=['4분위', '3분위', '2분위', '1분위'])\n",
    "    age_missing_by_spending = df_temp.groupby('spending_quertile')['age'].apply(lambda x: x.isnull().mean())  # 분위별로 그룹을 짓고, 그룹별로 각 값에 isnull(T/F로 변환)을 적용 후 평균(T/F는 1/0)을 계산\n",
    "    print('\\n 💲구매액 분위별 나이 결측률')\n",
    "    for key, value in age_missing_by_spending.items():\n",
    "        print(f' {key}: {value:.1%}')\n",
    "        \n",
    "    con_table = pd.crosstab(df_temp['spending_quertile'], df_temp['age'].isnull())\n",
    "    chi2, p_value, _, _ = chi2_contingency(con_table)\n",
    "\n",
    "    # print(f'\\n카이^2 통계량: {chi2:.3f}, p-value: {p_value:.4f}')\n",
    "    if p_value < 0.05:\n",
    "        print(' ✅MAR 확인: 구매액에 따라 나이 결측률이 유의미하게 다름')\n",
    "    else:\n",
    "        print(' ❌MCAR 가능성 있음: 구매액과 나이 결측률은 서로 독립적')\n",
    "\n",
    "else:\n",
    "    print(' 나이(age) 결측 없음')\n",
    "    \n",
    "    \n",
    "# 만족도 결측 패턴 분석\n",
    "print('\\n2. 만족도(satisfaction_score) 결측 메커니즘 분석')\n",
    "\n",
    "if ecommerce['satisfaction_score'].isna().sum():\n",
    "    # 연령대별 만족도 결측률 [0, 30, 50, 100] - [청년층(~30), 중년층(31~50), 노년층(51~)]\n",
    "    # 각 구간마다 만족도가 없는 사람들의 %를 구해서 print\n",
    "    print('\\n 🧓연령별 만족도 결측률')\n",
    "    df_temp = ecommerce.copy()\n",
    "    df_temp['age_group'] = pd.cut(df_temp['age'].dropna(), bins=[0, 30, 50, 200], labels=['청년층', '중년층', '노년층'])\n",
    "    satisfaction_missing_by_age = df_temp.groupby('age_group')['satisfaction_score'].apply(lambda x: x.isnull().sum() / len(x))\n",
    "\n",
    "    for key, value in satisfaction_missing_by_age.items():\n",
    "        print(f' {key}: {value:.1%}')\n",
    "\n",
    "    con_table = pd.crosstab(df_temp['age_group'], df_temp['satisfaction_score'].isnull())\n",
    "    chi2, p_value, _, _ = chi2_contingency(con_table)\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        print(' ✅MAR 확인: 연령에 따라 만족도 결측률이 유의미하게 다름')\n",
    "    else:\n",
    "        print(' ❌MCAR 가능성 있음: 연령과 만족도 결측률은 서로 독립적')\n",
    "\n",
    "\n",
    "    # 성별별 만족도 결측률도\n",
    "    print('\\n ♂️성별별 만족도 결측률')\n",
    "\n",
    "    df_temp = ecommerce.copy()\n",
    "    satisfaction_missing_by_gender = df_temp.groupby('gender')['satisfaction_score'].apply(lambda x: x.isnull().sum() / len(x))\n",
    "\n",
    "    for key, value in satisfaction_missing_by_gender.items():\n",
    "        print(f' {key}: {value:.1%}')\n",
    "\n",
    "\n",
    "    con_table = pd.crosstab(df_temp['gender'], df_temp['satisfaction_score'].isnull())\n",
    "    chi2, p_value, _, _ = chi2_contingency(con_table)\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        print(' ✅MAR 확인: 성별에 따라 만족도 결측률이 유의미하게 다름')\n",
    "    else:\n",
    "        print(' ❌MCAR 가능성 있음: 성별과 만족도 결측률은 서로 독립적')\n",
    "        \n",
    "else:\n",
    "    print(' 만족도 결측 없음')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5294702",
   "metadata": {},
   "source": [
    "## 고급 결측값 대체 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc6636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute: 대체하다\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# 숫자형 컬럼만 뽑기\n",
    "numeric_cols = ['age', 'total_purchases', 'avg_order_value', 'days_since_last_purchase', 'satisfaction_score']\n",
    "df_numeric = ecommerce[numeric_cols]\n",
    "print('원본데이터 결측률')\n",
    "for col in numeric_cols:\n",
    "    missing_rate = df_numeric[col].isnull().mean()\n",
    "    if missing_rate:\n",
    "        print(f'  {col}: {missing_rate:.2%}')\n",
    "\n",
    "# 1. 결측에 전부 평균을 집어넣었음\n",
    "imputer_mean = SimpleImputer(strategy='mean')\n",
    "df_mean = df_numeric.copy()\n",
    "df_mean[numeric_cols] = imputer_mean.fit_transform(df_numeric[numeric_cols])\n",
    "\n",
    "\n",
    "# 2. KNN 대체 - K Nearest Neighbors, 결측값과 가장 가까운 n명을 뽑아서 그 사람들의 평균을 구함\n",
    "imputer_knn = KNNImputer(n_neighbors=5)\n",
    "df_knn = df_numeric.copy()\n",
    "df_knn[numeric_cols] = imputer_knn.fit_transform(df_numeric[numeric_cols])\n",
    "\n",
    "\n",
    "# 3. MICE 대체 - Multiple Imputation by Chained Equations, 결측변수를 다른 변수를 써서 회귀모델 예측\n",
    "imputer_mice = IterativeImputer(random_state=42, max_iter=10)\n",
    "df_mice = df_numeric.copy()\n",
    "df_mice[numeric_cols] = imputer_mice.fit_transform(df_numeric[numeric_cols])\n",
    "\n",
    "# age 변수의 대체결과 비교 시각화\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15,10))\n",
    "a1, a2, a3, a4 = axes[0,0], axes[0,1], axes[1,0], axes[1,1]\n",
    "\n",
    "variable = 'age'\n",
    "if df_numeric[variable].isnull().sum():\n",
    "    \n",
    "    sns.histplot(df_mean[variable], binwidth=2, kde=False, ax=a1, label='평균', color='blue')\n",
    "    sns.histplot(df_numeric[variable], binwidth= 2, kde=False, ax=a1, label='원본', color='lightblue', alpha=0.3)\n",
    "    a1.set_xlim(0, 100)\n",
    "    a1.set_title('평균')\n",
    "        \n",
    "    sns.histplot(df_knn[variable], binwidth= 2, kde=False, ax=a2, label = 'KNN', color='coral')\n",
    "    sns.histplot(df_numeric[variable], binwidth= 2, kde=False, ax=a2, label='원본', color='lightcoral', alpha=0.3)\n",
    "    a2.set_xlim(0, 100)\n",
    "    a2.set_title('KNN')\n",
    "\n",
    "    sns.histplot(df_mice[variable], binwidth= 2, kde=False, ax=a3, label = 'mice', color='green')\n",
    "    sns.histplot(df_numeric[variable], binwidth= 2, kde=False, ax=a3, label='원본', color='lightgreen', alpha=0.3)\n",
    "    a3.set_xlim(0, 100)\n",
    "    a3.set_title('mice')\n",
    "    \n",
    "    \n",
    "    # 대체 전후 통계량 비교\n",
    "    comparison_stats = pd.DataFrame({\n",
    "        '원본': df_numeric[variable].describe(),\n",
    "        '평균': df_mean[variable].describe(),\n",
    "        'KNN': df_knn[variable].describe(),\n",
    "        'mice': df_mice[variable].describe(),\n",
    "    }).round(2)\n",
    "    \n",
    "    # 텍스트로 통계 비교 표시\n",
    "    a4.axis('off')\n",
    "    a4.table(\n",
    "        cellText=comparison_stats.values,\n",
    "        rowLabels=comparison_stats.index,\n",
    "        colLabels=comparison_stats.columns,\n",
    "        cellLoc='center',\n",
    "        loc='center',\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998fe331",
   "metadata": {},
   "source": [
    "## 대체 품질 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c895e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== 대체 품질 평가 ===')\n",
    "dist_evaluation_results = []\n",
    "corr_evaluation_results = []\n",
    "original_df = df_numeric\n",
    "imputed_dfs = [df_mean, df_knn, df_mice ]\n",
    "method_names = ['평균대체', 'KNN대체', 'MICE대체']\n",
    "\n",
    "for method_name, imputed_df in zip(method_names, imputed_dfs):\n",
    "    \n",
    "    for col in ['age','satisfaction_score']:\n",
    "        # 1. 분포 유사성 평가\n",
    "        # 결측치가 있는 경우만\n",
    "        if original_df[col].isnull().sum():\n",
    "            \n",
    "            original_stats = original_df[col].dropna().describe()\n",
    "            imputed_stats = imputed_df[col].describe()\n",
    "            \n",
    "            # 평균차이\n",
    "            mean_diff = abs(original_stats['mean'] - imputed_stats['mean']) / original_stats['mean'] * 100\n",
    "            # 표준편차차이\n",
    "            std_diff = abs(original_stats['std'] - imputed_stats['std']) / original_stats['std'] * 100\n",
    "            \n",
    "            dist_evaluation_results.append({\n",
    "                '방법': method_name,\n",
    "                '변수': col,\n",
    "                '평균차이(%)': mean_diff,\n",
    "                '표준편차차이(%)': std_diff,\n",
    "            })\n",
    "\n",
    "        # 2. 다른 변수와의 상관관계 보존 평가 - age, satisfaction_score <-> average_order_value\n",
    "        # 이건 실제로 상관관계가 있는 걸로 평가해야 함\n",
    "            original_corr = original_df[[col, 'avg_order_value']].corr().iloc[0, 1]  # 결측치 포함\n",
    "            imputed_corr = imputed_df[[col, 'avg_order_value']].dropna().corr().iloc[0, 1]  # 결측치 대체\n",
    "        \n",
    "            # 상관관계 유지도\n",
    "            corr_preservation = abs(original_corr - imputed_corr) / abs(original_corr) * 100\n",
    "            \n",
    "            corr_evaluation_results.append({\n",
    "                '방법': method_name,\n",
    "                '변수': f'{col}-구매액 상관관계',\n",
    "                '원본상관계수': original_corr,\n",
    "                '대체상관계수': imputed_corr,\n",
    "                '상관계수보존도(%)': 100 - corr_preservation,\n",
    "            })\n",
    "        \n",
    "print('\\n1. 분포 보존 성능')\n",
    "dist_eval = pd.DataFrame(dist_evaluation_results) \n",
    "display(dist_eval)\n",
    "\n",
    "print('\\n2. 상관관계 보존 성능')\n",
    "corr_eval = pd.DataFrame(corr_evaluation_results)\n",
    "for _, row in corr_eval.iterrows():\n",
    "    print(f'{row['방법']}: 보존도 {row['상관계수보존도(%)']:.1f}%')\n",
    "    print(f'(원본: {row['원본상관계수']:.3f} → 대체후: {row['대체상관계수']:.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c0285f",
   "metadata": {},
   "source": [
    "## 이상값 탐지 및 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c02d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 종합 이상값 탐지 ===\n",
      "\n",
      "1. 일변량 이상값 탐지(IQR법)\n",
      "  age: 12개 (1.2%)\n",
      "  avg_order_value: 70개 (7.0%)\n",
      "  days_since_last_purchase: 48개 (4.8%)\n",
      "\n",
      "2. 다변량 이상값 탐지(마할라노비스 거리)\n",
      "  임계값: 4.53\n",
      "  마할라노비스 거리 이상값: 11개 (1.1%)\n",
      "\n",
      "3. 다변량 이상값 탐지(Isolation Forest)\n",
      "  Isolation Forest 이상값: 127개 (12.7%)\n",
      "\n",
      "4. 비즈니스 규칙 기반 이상값 탐지\n",
      "  비즈니스 규칙 이상값: 7개 (0.7%)\n",
      "\n",
      " == 최종 이상값: 73개 (7.3%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IQR</th>\n",
       "      <th>마할라노비스 거리</th>\n",
       "      <th>Isolation Forest</th>\n",
       "      <th>비즈니스</th>\n",
       "      <th>총이상값수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       IQR  마할라노비스 거리  Isolation Forest   비즈니스  총이상값수\n",
       "0    False      False             False  False      0\n",
       "1    False      False             False  False      0\n",
       "2    False      False             False  False      0\n",
       "3    False      False             False  False      0\n",
       "4    False      False             False  False      0\n",
       "..     ...        ...               ...    ...    ...\n",
       "995   True      False              True  False      2\n",
       "996  False      False              True  False      1\n",
       "997  False      False              True  False      1\n",
       "998  False      False             False  False      0\n",
       "999  False      False             False  False      0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# 경고메세지 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "\n",
    "# 범용 이상치 탐지 함수\n",
    "def outlier_detection(df: pd.DataFrame, chi_q=0.999, iso_contamination=0.1, final_threshold=2):\n",
    "    print('=== 종합 이상값 탐지 ===')\n",
    "    df_copy = df.copy()\n",
    "    numeric_data = df_copy.select_dtypes(include=['number'])\n",
    "    \n",
    "    # 1. IQR 이상값(일(단)변량 이상값 탐지) - 변수 하나를 가지고 확인\n",
    "        # 특정 컬럼 안에서 다른 값들에 비해 값이 이상한 걸 탐지함\n",
    "    print('\\n1. 일변량 이상값 탐지(IQR법)')\n",
    "    univariate_outliers = pd.DataFrame(index=df_copy.index)\n",
    "    \n",
    "    for col in numeric_data.columns:\n",
    "        Q1 = df_copy[col].quantile(0.25)\n",
    "        Q3 = df_copy[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers_mask = (df_copy[col] < lower_bound) | (df_copy[col] > upper_bound)\n",
    "        univariate_outliers[col] = outliers_mask\n",
    "        \n",
    "        outlier_count = outliers_mask.sum()\n",
    "        if outlier_count:\n",
    "            print(f'  {col}: {outlier_count}개 ({outlier_count/len(df_copy) * 100:.1f}%)')\n",
    "\n",
    "    # 2. 마할라노비스 거리 기반 다변량 이상값\n",
    "        # 변수 간의 스케일 차이와 상관관계까지 고려해 이상값을 확인\n",
    "        # 특정 컬럼이 이상한게 아니라, 종합적으로 데이터 행 하나하나가 이상한가를 보여준다\n",
    "        # 데이터가 정규분포를 따를 때 유용함(데이터가 대부분 정상으로 보이지만, 이상값을 찾고 싶을 때 사용) - 대놓고 이상한 데이터가 한가득일 때는 제대로 작동 안함. \n",
    "    print('\\n2. 다변량 이상값 탐지(마할라노비스 거리)')\n",
    "    \n",
    "    # 변수 간 스케일 차이 변환\n",
    "        # standard scaler - 모든 데이터를 표준편차 1, 평균 0으로 바꿔버림\n",
    "    scaler = StandardScaler()\n",
    "    scaled_df = pd.DataFrame(\n",
    "        scaler.fit_transform(numeric_data),\n",
    "        columns=numeric_data.columns,\n",
    "        index=numeric_data.index,\n",
    "    )\n",
    "    # 데이터 평균 벡터\n",
    "    mean = scaled_df.mean().values\n",
    "    # 공분산 행렬\n",
    "    cov_matrix = np.cov(scaled_df, rowvar=False)\n",
    "    # 공분산 행렬의 역행렬\n",
    "    inv_cov_matrix = np.linalg.pinv(cov_matrix)\n",
    "    \n",
    "    # 마할라노비스 거리 계산\n",
    "    mahalanobis_dist = scaled_df.apply(lambda row: distance.mahalanobis(row, mean, inv_cov_matrix), axis=1)\n",
    "    \n",
    "    # 이상치 기준점(threshold) 지정 (카이제곱 분포 -> 정상값을 몇 퍼센트(95% / 99% / 99.9%)까지 인정할 수 있는가)\n",
    "    threshold = chi2.ppf(chi_q, len(numeric_data.columns)) ** 0.5\n",
    "    mahalanobis_outliers = mahalanobis_dist > threshold\n",
    "    print(f'  임계값: {threshold:.2f}')\n",
    "    print(f'  마할라노비스 거리 이상값: {mahalanobis_outliers.sum()}개 ({mahalanobis_outliers.mean() * 100:.1f}%)')\n",
    "    \n",
    "    # 3. Isolation Forest 기반 다변량 이상값\n",
    "        # 랜덤한 기준으로 구분하는 독립된 Tree 여러개를 만들어서 얼마나 빨리 고립되는지를 확인하는 과정\n",
    "        # 데이터 간의 관계가 복잡해 이상치가 복잡하게 숨어있을 때 이용함 - 매우 공격적으로 이상치를 검출, 대놓고 수상한 데이터들을 잘 골라준다\n",
    "    print('\\n3. 다변량 이상값 탐지(Isolation Forest)')\n",
    "    # contamination = 전체에서 얼마나 이상값 비율이 있을것인가 예측. 'auto'로 알아서 고르라 할 수 있다.\n",
    "    iso_forest = IsolationForest(contamination=iso_contamination, random_state=42)\n",
    "    iso_outliers = iso_forest.fit_predict(scaled_df) == -1\n",
    "    iso_scores = iso_forest.score_samples(scaled_df)\n",
    "    print(f'  Isolation Forest 이상값: {iso_outliers.sum()}개 ({iso_outliers.mean() * 100:.1f}%)')    \n",
    "    \n",
    "    # 4. 비즈니스 규칙(특화) 이상값\n",
    "        # 굳이 복잡한 방법을 쓰지 말고, 각 컬럼별로 이상값 기준을 정해준 뒤 그 기준에 맞지 않으면 이상값으로 판정(사람은 130살 이상 살기 힘듦)\n",
    "        # 각 데이터마다 전용 기준이 필요함\n",
    "        \n",
    "    print('\\n4. 비즈니스 규칙 기반 이상값 탐지')\n",
    "    business_outliers = (\n",
    "        (df['age'] >130) |\n",
    "        (df['days_since_last_purchase'] < 0) |\n",
    "        (df['avg_order_value'] > 1000000) |\n",
    "        (df['avg_order_value'] < 0)\n",
    "    )\n",
    "    print(f'  비즈니스 규칙 이상값: {business_outliers.sum()}개 ({business_outliers.mean() * 100:.1f}%)')\n",
    "    \n",
    "    # 종합 판정\n",
    "    outlier_summary = pd.DataFrame({\n",
    "        'IQR': univariate_outliers.sum(axis=1) > 0,\n",
    "        '마할라노비스 거리': mahalanobis_outliers,\n",
    "        'Isolation Forest': iso_outliers,\n",
    "        '비즈니스': business_outliers,\n",
    "    })\n",
    "    \n",
    "    outlier_summary['총이상값수'] = outlier_summary.sum(axis=1)\n",
    "    outlier_final = outlier_summary['총이상값수'] >= final_threshold\n",
    "    print(f'\\n == 최종 이상값: {outlier_final.sum()}개 ({outlier_final.mean() * 100:.1f}%)')\n",
    "    \n",
    "    return outlier_summary\n",
    "    \n",
    "outlier_detection(df_knn, chi_q=0.999, iso_contamination='auto', final_threshold=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
