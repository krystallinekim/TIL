{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6161bd71",
   "metadata": {},
   "source": [
    "# 랭체인 입문\n",
    "\n",
    "LLM powered application 제작을 위한 프레임워크\n",
    "\n",
    "## 랭체인 기초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bc8897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0587004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4416abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! Nice to meet you. If you’re just testing, I’m here to help with whatever you need. Want a quick Hello, World! example in a specific language, or something else? Here are a few quick snippets:\\n\\n- Python: print(\"Hello, World!\")\\n- JavaScript: console.log(\"Hello, World!\")\\n- C: #include <stdio.h>\\n  int main(void) { printf(\"Hello, World!\"); return 0; }\\n\\nTell me what you’re trying to do, and I’ll tailor it.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 822, 'prompt_tokens': 10, 'total_tokens': 832, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 704, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CArY3UtrKsHxsXecQVJrdKz6acDJe', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--487dc7fd-a43e-4c5e-80f6-a3c58e2e7331-0', usage_metadata={'input_tokens': 10, 'output_tokens': 822, 'total_tokens': 832, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 704}})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-5-nano')\n",
    "llm.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44478d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What should I eat for lunch?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 외국어 -> 한국어로 번역하는 작업\n",
    "\n",
    "msg = input('외국어')\n",
    "\n",
    "res = llm.invoke(f'다음 내용을 한국어로 번역해줘: {msg}')\n",
    "\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0a6600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What should I eat for lunch?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    # 채팅 세션의 전체적인 안내사항\n",
    "    SystemMessage(content='다음 내용을 영어로 번역해줘'),\n",
    "    HumanMessage(content='점심 뭐먹지')\n",
    "]\n",
    "\n",
    "res = llm.invoke(messages)\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ea981e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What should I have for lunch?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    # SystemMessage(content='다음 내용을 영어로 번역해줘'),\n",
    "    {'role': 'system', 'content': '다음 내용을 영어로 번역해줘'},\n",
    "    # HumanMessage(content='점심 뭐먹지'),\n",
    "    {'role': 'user', 'content': '점심 뭐먹지'}\n",
    "]\n",
    "\n",
    "res = llm.invoke(messages)\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8bb0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|What| should| I| have| for| lunch|?||"
     ]
    }
   ],
   "source": [
    "for token in llm.stream(messages):\n",
    "    print(token.content, end='|')\n",
    "    \n",
    "# 일반적으로 답변 생성 시 토큰별로 생성해서 보여주는 편"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b0869",
   "metadata": {},
   "source": [
    "## 프롬프트 템플릿\n",
    "\n",
    "고정된 문자열과 변수를 조합해 프롬프트를 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2579b884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='今日の昼ご飯、美味しかったですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 30, 'total_tokens': 49, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAqctpUGCR22UBYOXLCZ8aB0hCr1P', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--5cf50841-71de-4577-8ff7-a8d196d809f0-0', usage_metadata={'input_tokens': 30, 'output_tokens': 19, 'total_tokens': 49, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': 'translate korean to {lang}'},\n",
    "    {'role': 'user', 'content': '{text}'}\n",
    "]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "prompt = prompt_template.invoke({'lang': 'japanese', 'text': '오늘 점심 맛있었어'})\n",
    "# 이 전체가 묶여서 템플릿으로 만들어진것\n",
    "\n",
    "prompt.to_messages()\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ed4405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Das ist egal, ob es Frankreich oder Deutschland ist.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 35, 'total_tokens': 47, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAqgqgf9xT1kxY1AQjoTowYkXDMBO', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--7d8fb9ee-4938-4651-98ca-8078be78340e-0', usage_metadata={'input_tokens': 35, 'output_tokens': 12, 'total_tokens': 47, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 템플릿이 있으니까 일부만 바꿔도 알아서 전체에 적용해준다.\n",
    "prompt = prompt_template.invoke({'lang': 'Deutsch', 'text': '프랑스나 독일이나 거기서 거기임'})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd87653b",
   "metadata": {},
   "source": [
    "## 체인\n",
    "- langchain의 각 구성요소를 묶어서(Chaining) 한번에 실행(invoke) 할 수 있는 기능\n",
    "- `a | b | c | ...`의 형태 -> 파이썬 문법이 아니라, 랭체인 문법(LangChain Expression Language, LCEL)\n",
    "- 기본적으로 프롬프트부터 시작함\n",
    "- 파이프 안에 다른게 계속 들어가짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e4a572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'annibyniaeth i Gymru'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 체인 -> 원하는 조건을 프롬프트 템플릿에 적용 - 템플릿으로 AI에서 결과를 만듦 - 결과물 해석까지 연이어서 할 수 있다\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt_template | llm | output_parser\n",
    "chain.invoke({'lang': 'Welsh ', 'text': '웨일스에 독립을'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16ec9381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음은 “25년 전반기 매출 분석”을 EDA(탐색적 데이터 분석) 관점에서 단계별로 나눈 실행 로드맷입니다. 각 단계는 실제 분석 흐름에 맞춰 구체적 작업으로 구성했습니다.\n",
      "\n",
      "1) 분석 목표 정의 및 범위 설정\n",
      "- 기간 정의: 2025년 1월 1일 ~ 2025년 6월 30일(H1 2025)\n",
      "- 핵심 지표(KPI)\n",
      "  - 매출액(Revenue), 주문건수(Orders), 평균 주문가(AOV)\n",
      "  - 카테고리별 매출, 지역별 매출\n",
      "  - 원가/이익(Gross Profit, Margin)\n",
      "  - 채널/프로모션 영향 분석 여부\n",
      "- 비교 기준\n",
      "  - 2024년 H1 또는 최근 비슷한 기간과의 YoY 비교\n",
      "- 산출물 형식\n",
      "  - 요약 인사이트 리포트, 데이터 품질 로그, 재현 가능한 노트북/스크립트, 시각화 대시보드 초안\n",
      "\n",
      "2) 데이터 소스 파악 및 품질 진단\n",
      "- 필요한 데이터 아이템(예시)\n",
      "  - 거래/매출 데이터: OrderDate, Revenue, Quantity, UnitPrice, Discount, Cost, Profit, OrderID\n",
      "  - 차원 데이터: CustomerRegion, ProductCategory, Channel, PromotionFlag, ProductID/Name\n",
      "  - 마스터 데이터(선택): Customer, Product, Region/Stores\n",
      "- 데이터 품질 점검\n",
      "  - 누락(missing), 중복(duplicate), 기간 필터링(2025년 H1에 해당하는 주문만)\n",
      "  - 통화/통화 단위의 일관성, 음수값 여부, 이상치(outliers) 여부\n",
      "  - 날짜 형식 및 시계열 정합성 확인\n",
      "- 데이터 흐름 문서화\n",
      "  - 소스-변환-로딩(ETL) 파이프라인 개략도 작성\n",
      "\n",
      "3) 데이터 준비 및 구조화\n",
      "- 데이터 통합\n",
      "  - 거래 데이터와 차원 데이터(카테고리, 지역, 채널, 프로모션) 조인\n",
      "- 파생 변수 생성\n",
      "  - Year, Month, Day, HalfYear(H1/H2) 또는 PeriodLabel(2025-01, 2025-02, …)\n",
      "  - 프로모션 여부, 할인률, 마진/이익 지표 등\n",
      "- 데이터 정제\n",
      "  - 중복 제거, 이상치 처리 가이드라인, 필요한 경우 통화 단위 표준화\n",
      "- 샘플링: 분석 속도 및 재현성을 위한 샘플링 정책 정의\n",
      "- 버전 관리 및 기록\n",
      "  - 데이터 스냅샷, 스키마 변경 로그\n",
      "\n",
      "4) 탐색적 데이터 분석(EDA) 계획 수립\n",
      "- Univariate 분석\n",
      "  - 매출 분포(전체/카테고리/지역별), 주문 수 분포, 평균 주문액(AOV) 분포\n",
      "- Bivariate/다변량 분석\n",
      "  - 매출 vs 카테고리, 매출 vs 지역, 매출 vs 채널, 프로모션 여부에 따른 차이\n",
      "  - 할인율과 이익 간 관계\n",
      "- Time series 분석 초안\n",
      "  - 월간 매출 추세(2025년 1월 ~ 6월)\n",
      "  - Moving average(예: 2-3개월), 증감률 및 MOM/YoY 비교\n",
      "- 비교 분석\n",
      "  - 2025 H1 vs 2024 H1: 총 매출, 카테고리 기여도, 지역별 차이\n",
      "  - 캠페인/프로모션 기간의 효과 파악\n",
      "- 구간/세그먼트 분석 제안\n",
      "  - 카테고리별 Top N 항목, 지역별 Top 고객군(필요 시)\n",
      "\n",
      "5) 가설 설정 및 분석 방법\n",
      "- 예시 가설\n",
      "  - H1 2025 매출은 H1 2024 대비 증가했다.\n",
      "  - 특정 카테고리(예: 전자/가전)가 H1에서 매출의 큰 비중을 차지한다.\n",
      "  - 특정 지역에서 프로모션 효과가 매출 증가에 기여했다.\n",
      "- 검정 및 비교 방법\n",
      "  - YoY/MoM 성장률, 차이의 통계적 유의성 여부(적합 시 t-test/비모수 검정)\n",
      "  - 카테고리/지역별 벤치마크와의 차이 분석\n",
      "  - 프로모션 영향은 차이의 차로 분석(Difference-in-Differences 가능 시)\n",
      "\n",
      "6) 시각화 및 대시보드 설계\n",
      "- KPI 대시보드(핵심 지표 카드)\n",
      "  - 2025 H1 총매출, 총주문수, 평균주문가, 총이익\n",
      "- 시계열 시각화\n",
      "  - 월별 매출 선 그래프, 2025 H1의 월별 추세 및 2개월 간의 이동평균\n",
      "- 분류별 시각화\n",
      "  - 카테고리별 매출 바 차트, 지역별 매출 지도/바 차트\n",
      "- 비교/상관 시각화\n",
      "  - 2025 H1 vs 2024 H1 YoY 비교 바 차트\n",
      "  - 프로모션 여부에 따른 매출 차트(스티키 차트)\n",
      "- 추가 차트 아이디어\n",
      "  - Heatmap(지역-카테고리 매출 집중도), 스택형 영역 차트(채널별 매출 구성)\n",
      "- 대시보드 샘플 포맷\n",
      "  - 이해관계자 의사결정용 요약+세부 분석 페이지\n",
      "\n",
      "7) 산출물 정리 및 재현성 확보\n",
      "- 산출물 목록\n",
      "  - 분석 리포트: 요약 인사이트, 수치 표, 시각화\n",
      "  - 데이터 품질 로그: 발견된 누락/이상치/정제 방법\n",
      "  - 재현 스노우플레이크/노트북/스크립트: 코드 주석 포함\n",
      "  - 대시보드 초안/샘플 대시보드 파일\n",
      "- 재현성 팁\n",
      "  - 데이터 소스 경로, 필터 조건, 버전 관리된 데이터 스냅샷 명시\n",
      "  - 실행 순서가 명확한 워크플로우(ETL → EDA → 시각화)\n",
      "\n",
      "8) 실행 계획 및 일정 제안\n",
      "- 권장 기간: 1–2주\n",
      "  - 1단계(목표·데이터 파악): 0.5주\n",
      "  - 2단계(데이터 준비/정제): 0.5주\n",
      "  - 3단계(EDA 실행): 0.5주\n",
      "  - 4단계(시각화/리포트 작성): 0.5주\n",
      "- 중간 점검 포인트\n",
      "  - 데이터 품질 이슈 및 전처리 합의\n",
      "  - 주요 인사이트에 대한 이해관계자 피드백\n",
      "\n",
      "9) 주의사항 및 제약사항\n",
      "- 데이터의 커버리지: 2025년 H1 데이터의 완전성 확인 필요\n",
      "- 카테고리/지역 정의의 변경 여부: 기간 동안 정책 변경 시 해석 포인트\n",
      "- 프로모션/할인 데이터의 정확성: 할인 정책의 적용 범위와 시점 확인\n",
      "\n",
      "10) 확장 및 차후 분석 제안\n",
      "- 2H 2025 예측/예측 모델링\n",
      "  - Prophet, ARIMA 등으로 2H 2025 매출 예측\n",
      "- 시나리오 분석\n",
      "  - 프로모션 강도, 가격 정책 변화 시나리오에 따른 매출/이익 영향 예측\n",
      "- 세부 인사이트 심화\n",
      "  - 고객 세그먼트별 재구매율, LTV 분석 등\n",
      "\n",
      "데이터 스키마 예시(필수는 아니지만 참고용)\n",
      "- 거래 데이터: OrderID, OrderDate, CustomerID, ProductID, ProductCategory, Region, Channel, Quantity, UnitPrice, Discount, Revenue, Cost, Profit\n",
      "- 차원 데이터: CustomerID -> CustomerName, Region, Country, Segment; ProductID -> ProductName, ProductCategory; PromotionFlag, PromotionName\n",
      "- 파생 변수: Year, Month, HalfYear(H1/H2), PeriodLabel(YYYY-MM)\n",
      "\n",
      "추가로 원하시면 아래를 알려 주세요\n",
      "- 실제 데이터의 예시 필드와 형식\n",
      "- 데이터 수집 소스(데이터베이스, CSV, BI 도구 등)\n",
      "- 비교 기준 대상(예: 2024 H1 vs 2025 H1)\n",
      "- 원하는 시각화 형태나 대시보드 도구(Excel, Power BI, Tableau, Python 대시보드 등)\n",
      "\n",
      "원하시면 위의 단계들을 기반으로 당신의 데이터 상황에 맞춘 맞춤형 체크리스트와 실행 노트를 바로 만들어 드리겠습니다.\n"
     ]
    }
   ],
   "source": [
    "# ChatPromptTemplate -> 채팅을 할 때 씀\n",
    "# PromptTemplate -> 한번, 단발성으로 사용할 때 쓴다\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = '''\n",
    "당신은 클라이언트의 요구 사항을 분석해서 단계를 나눠주는 데이터 분석 전문가입니다.\n",
    "사용자의 질문을 EDA에 활용할 수 있도록 단계를 나누어 주세요.\n",
    "\n",
    "질문: {question}\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "res = chain.invoke({'question': '25년 전반기 매출 분석'})\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "991b5186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^1^.^ 요^구^ 사^항^ 분^석^\n",
      "^  ^ -^ 클^라^이^언^트^가^ 원^하는^ 분^석^ 목^표^ 및^ 목^적^ 파^악^\n",
      "^  ^ -^ 데이터^ 수^집^ 및^ 가^용^성^ 확인^\n",
      "^  ^ -^ 클^라^이^언^트^가^ 원^하는^ 결과^물^ 및^ 보^고^서^ 형^식^ 결^정^\n",
      "   \n",
      "^2^.^ 데이터^ 전^처^리^\n",
      "^  ^ -^ 데이터^ 수^집^ 및^ 크^기^ 확인^\n",
      "^  ^ -^ 데이터^의^ 결^측^치^,^ 이^상^치^,^ 중^복^값^ 등^의^ 처리^\n",
      "^  ^ -^ 데이터^의^ 형^식^ 변^환^ 및^ 범^주^형^ 데이터^ 인^코^딩^\n",
      "^  ^ -^ 데이터^의^ 스^케^일^링^ 및^ 정^규^화^\n",
      "   \n",
      "^3^.^ 탐^색^적^ 데이터^ 분^석^ (^EDA^)\n",
      "^  ^ -^ 데이터^의^ 분^포^ 및^ 통^계^량^ 확인^\n",
      "^  ^ -^ 변수^ 간^ 상^관^ 관^계^ 및^ 패^턴^ 파^악^\n",
      "^  ^ -^ 데이터^ 시^각^화^를^ 통^한^ 인^사^이^트^ 도^출^\n",
      "^  ^ -^ 특^징^ 선택^ 및^ 차^원^ 축^소^ 기^법^ 적^용^\n",
      "   \n",
      "^4^.^ 모^델^링^\n",
      "^  ^ -^ 분^석^ 목^표^에^ 맞^는^ 모^델^ 선택^\n",
      "^  ^ -^ 학^습^ 및^ 테^스트^ 데이터^ 셋^ 분^리^\n",
      "^  ^ -^ 모^델^ 학^습^ 및^ 튜^닝^\n",
      "^  ^ -^ 모^델^ 성^능^ 평^가^ 및^ 검^증^\n",
      "   \n",
      "^5^.^ 결과^ 해^석^ 및^ 보^고^\n",
      "^  ^ -^ 모^델^ 결과^ 해^석^ 및^ 클^라^이^언^트^에^게^ 설^명^\n",
      "^  ^ -^ 모^델^의^ 성^능^ 및^ 결과^물^ 평^가^\n",
      "^  ^ -^ 결^론^ 도^출^ 및^ 추^후^ 전^략^ 제^안^\n",
      "^  ^ -^ 보^고^서^ 작^성^ 및^ 발^표^\n",
      "\n",
      "^이^와^ 같^은^ 단^계^를^ 따^라^가^면^ 보^다^ 체^계^적^이^고^ 효^율^적^인^ 데이터^ 분^석^ 프^로^젝^트^가^ 가능^할^ 것^입니다^.^^"
     ]
    }
   ],
   "source": [
    "# Stream\n",
    "for token in chain.stream({'question': '보편적인 분석 프로젝트 진행'}):\n",
    "    print(token, end='^', flush=True)\n",
    "    \n",
    "# 일반적인 LLM에서 답변을 보여주는 방식이 이렇다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d96150b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Langchain은 여러 가지 언어모델과 도구들을 연결하여 자연어 처리 애플리케이션을 쉽게 구축할 수 있도록 돕는 프레임워크입니다. 이를 통해 챗봇이나 자동화된 질문응답 시스템 등 복잡한 AI 기반 작업을 효율적으로 개발할 수 있습니다. 또한, 데이터 소스와의 통합과 사용자 맞춤형 응답 생성 등을 지원하여 다양한 산업 분야에서 활용되고 있습니다.',\n",
       " 'Langsmith는 OpenAI가 개발한 강력한 언어 모델 플랫폼으로, 사용자들이 자연어 처리 작업을 쉽게 수행할 수 있도록 지원합니다. 이 플랫폼은 텍스트 생성, 요약, 번역 등의 다양한 언어 관련 기능을 통합하여 제공하며, 개발자들이 맞춤형 AI 애플리케이션을 구축할 수 있도록 돕습니다. 또한, 사용자 친화적인 인터페이스와 API를 통해 빠른 개발과 효율적인 통합이 가능하게 설계되어 있습니다.',\n",
       " 'LangGraph는 자연어 처리(NLP) 분야에서 언어 구조를 그래프로 표현하는 기법입니다. 이를 통해 문장 내 단어와 의미 간의 관계를 시각화하고 분석할 수 있습니다. LangGraph는 언어 이해와 텍스트 분석의 정밀도를 높이기 위해 다양한 관계망과 연결 구조를 활용합니다.']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch는 몇개를 동시에 한 프롬프트 템플릿에 넣을 때 사용함\n",
    "\n",
    "prompt = PromptTemplate.from_template('{topic}에 대해 3문장으로 설명해줘')\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano')\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "chain.batch([\n",
    "    {'topic': 'Langchain'},\n",
    "    {'topic': 'Langsmith'},\n",
    "    {'topic': 'Langgraph'}\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa6f99e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
