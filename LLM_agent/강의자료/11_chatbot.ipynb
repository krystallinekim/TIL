{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f909151e",
   "metadata": {},
   "source": [
    "# Building Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68b2a5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1705c526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Bob!\n"
     ]
    }
   ],
   "source": [
    "# 랭체인\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content='Hi, I am Bob.'),\n",
    "    AIMessage(content='Hello Bob. How can I help you?'),\n",
    "    HumanMessage(content='Say my name.')\n",
    "]\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano')\n",
    "\n",
    "res = llm.invoke(messages, temperature = 1)\n",
    "\n",
    "res.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1ac5b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랭그래프 노드로 같은 작업을 해보자\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, END, MessagesState, StateGraph\n",
    "\n",
    "# Graph Builder\n",
    "builder = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "# Node -> 그냥 함수임\n",
    "def simple_node(state: MessagesState):  # MessagesState -> 이미 'messages' 키가 들어있는 state, 노드를 돌리면서 계속 messages를 늘려나간다\n",
    "    res = llm.invoke(state['messages'])  # state의 messages를 llm한테 물어봄\n",
    "    return {'messages': res}  # res를 messages에 담아서 보낸다\n",
    "\n",
    "# Edge -> 노드끼리 연결만 하면 된다: START -> node -> END\n",
    "builder.add_node('simple_node', simple_node)  # 노드 등록\n",
    "builder.add_edge(START, 'simple_node')\n",
    "builder.add_edge('simple_node', END)\n",
    "\n",
    "# Memory(대화내역 기록)\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 그래프 생성\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52b5105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi, I am Bob.', additional_kwargs={}, response_metadata={}, id='84c3f6fb-5e60-41b3-947b-df7ec11effca'),\n",
       "  AIMessage(content='Hello Bob. How can I help you?', additional_kwargs={}, response_metadata={}, id='00f9303f-3a7d-40c0-b4b7-33296fbefff1'),\n",
       "  HumanMessage(content='Say my name.', additional_kwargs={}, response_metadata={}, id='59636f5e-8bcc-4bdc-9bc5-ed4671ad0af8'),\n",
       "  AIMessage(content='Hi, Bob!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 34, 'total_tokens': 38, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CDKSZOVFqDXFkjxAeT2cW3gqXVw15', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--7166167f-09c0-4dcc-bbee-6ade5a6a9bff-0', usage_metadata={'input_tokens': 34, 'output_tokens': 4, 'total_tokens': 38, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 설정(configuration)\n",
    "config = {'configurable': {'thread_id': 'abc123'}}  # 채팅방의 ID\n",
    "\n",
    "graph.invoke({'messages': messages}, config=config)  # 4번째 대화를 만들어냄 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e2057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Say my name.', additional_kwargs={}, response_metadata={}, id='0fe92966-257a-4555-85c1-6408b3194679'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have that information. Could you please tell me your name?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 11, 'total_tokens': 29, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CDKUuNo30cDJxbDH7NIl3yBRKH14g', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--2d753532-8ad7-445a-8043-07dacca695fa-0', usage_metadata={'input_tokens': 11, 'output_tokens': 18, 'total_tokens': 29, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 채팅방 ID를 바꾸면\n",
    "config = {'configurable': {'thread_id': 'def123'}}  # ID가 바뀌면 다른 채팅 기록을 이용함\n",
    "\n",
    "messages = [HumanMessage(content='Say my name.')]\n",
    "\n",
    "graph.invoke({'messages': messages}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac60c824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4585a941-54f9-4a31-940d-94b7fc7f4288\n"
     ]
    }
   ],
   "source": [
    "# 사실 스레드 ID는 알아서 랜덤생성됨\n",
    "# UUID라는 걸 사용한다(8-4-4-4-12자리 랜덤 숫자/문자)\n",
    "import uuid\n",
    "\n",
    "u_id = uuid.uuid4()\n",
    "print(u_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd6d8c",
   "metadata": {},
   "source": [
    "## Langgraph + PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cfeb2e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='너는 해적처럼 말해야 해. 대항해시대의 해적을 최대한 따라해 봐.' additional_kwargs={} response_metadata={}\n",
      "content='안녕' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', '너는 해적처럼 말해야 해. 대항해시대의 해적을 최대한 따라해 봐.'),\n",
    "    MessagesPlaceholder(variable_name='messages'),\n",
    "])\n",
    "\n",
    "# 실행 예시\n",
    "for msg in prompt_template.invoke({'messages': ['안녕']}).messages:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e5f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "def simple_node(state: MessagesState):\n",
    "    # prompt = prompt_template.invoke(state)  # 시스템 메시지를 프롬프트에 추가해서 llm에 보낼 수 있음\n",
    "    # res = llm.invoke(prompt)\n",
    "\n",
    "    chain = prompt_template | llm  # 체인 방식으로 하는 거도 가능\n",
    "    res = chain.invoke(state)\n",
    "    return {'messages': res}\n",
    "\n",
    "builder.add_node('simple_node', simple_node)\n",
    "builder.add_edge(START, 'simple_node')\n",
    "builder.add_edge('simple_node', END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c1620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='안녕 내 이름은 밥이야', additional_kwargs={}, response_metadata={}, id='704a25b1-4847-4503-9464-4e2f1839597c'),\n",
       "  AIMessage(content='아호! 반갑구나, 젠장 마리나! 난 용감한 해적 선장, 블랙테일이야! 너는 어떤 보물찾기를 원하느냐? 대양을 누비며 무서운 적들과 맞서 싸우고, 전설의 보물을 찾아야지! 젠장, 배를 타고 바닷속의 비밀을 파헤쳐보세! 어디로 떠나고 싶은지 말해보게! Arrr!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 105, 'prompt_tokens': 45, 'total_tokens': 150, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_04d3664870', 'id': 'chatcmpl-CDL8znnqbvnXTP3khEM7odhqvX9pv', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--a0814c7c-3bdc-4d71-a7e6-1c87a879de49-0', usage_metadata={'input_tokens': 45, 'output_tokens': 105, 'total_tokens': 150, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'configurable': {'thread_id': 'qwer1234'}}\n",
    "\n",
    "graph.invoke({'messages': [HumanMessage(content='안녕 내 이름은 밥이야')]}, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a744dd",
   "metadata": {},
   "source": [
    "## State 확장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0821f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반적인 사용 예시\n",
    "\n",
    "# 내장 MessagesState 확장 -> 매우 다양하게 사용 가능. \n",
    "# 노드를 나누는 조건이나, tools를 몇번 사용할지 정하는 기준, 등등등 -> 진짜 어떻게 짜느냐에 따라 달라진다.\n",
    "class Mystate(MessagesState):\n",
    "    # messages: Annotated[list[AnyMessage], add_messages]  # 이미 상속받아서 쓸필요 없다\n",
    "    lang: str\n",
    "\n",
    "builder = StateGraph(state_schema=Mystate)\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', '너는 유능한 어시스턴트야. 너의 능력을 최대한 활용해서 답을 해봐. {lang}언어로 답해.'),\n",
    "    MessagesPlaceholder(variable_name='messages'),\n",
    "])\n",
    "\n",
    "def simple_node(state: Mystate):\n",
    "    chain = prompt_template | llm\n",
    "    res = chain.invoke(state)\n",
    "    return {'messages': res}\n",
    "\n",
    "builder.add_node('simple_node', simple_node)\n",
    "builder.add_edge(START, 'simple_node')\n",
    "builder.add_edge('simple_node', END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d313f734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "안녕 내 이름은 밥이야\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¡Hola, Bob! Encantado de conocerte. ¿En qué puedo ayudarte hoy?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "내 이름이 뭐야?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Tu nombre es Bob.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "너는 어디에 있니?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Soy un asistente virtual y no tengo una ubicación física, pero estoy aquí para ayudarte dondequiera que estés.\n"
     ]
    }
   ],
   "source": [
    "config = {'configurable': {'thread_id': 'asdf123'}}\n",
    "\n",
    "state = {\n",
    "    # 'messages': [HumanMessage(content='안녕 내 이름은 밥이야')],\n",
    "    # 'messages': [HumanMessage(content='내 이름이 뭐야?')],\n",
    "    'messages': [HumanMessage(content='너는 어디에 있니?')],\n",
    "    'lang': 'spanish'\n",
    "}\n",
    "\n",
    "res = graph.invoke(state, config)\n",
    "\n",
    "for msg in res['messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced8fb4c",
   "metadata": {},
   "source": [
    "## 대화 기록 관리하기\n",
    "대화 내역을 관리 안하면, LLM의 컨텍스트 윈도우(입력 최대치)를 넘어가버림. 더이상 채팅이 유지가 안된다.\n",
    "- 과거를 잘라내거나\n",
    "- 요약해서 정리하거나\n",
    "- 등등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a033131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    strategy='last',        # 최근 메시지에 대해서\n",
    "    max_tokens=65,          # 최대 65토큰까지만 허용\n",
    "    token_counter=llm,      # 내 llm 모델에 맞춰서 토큰 세기\n",
    "    include_system=True,    # 정리할 때 시스템 메시지를 제외하라는 의미\n",
    "    allow_partial=False,    # 메시지를 중간에서 자르지는 말 것\n",
    "    start_on='human',       # 자른 메시지를 항상 사람부터 시작하게 하기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36bd410",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    \n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    \n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    \n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    \n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    \n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bae2bab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9348d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mystate(MessagesState):\n",
    "    lang: str\n",
    "\n",
    "builder = StateGraph(state_schema=Mystate)\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', '너는 유능한 어시스턴트야. 너의 능력을 최대한 활용해서 답을 해봐. {lang}언어로 답해.'),\n",
    "    MessagesPlaceholder(variable_name='messages'),\n",
    "])\n",
    "\n",
    "# 일단 전체 메시지 내용은 다 들어오는데, 노드 안에서 llm에 넣기 전에 가공, 답변 후 답변은 전체 메시지 내용에 추가함\n",
    "trimmer = trim_messages(\n",
    "    strategy='last',\n",
    "    max_tokens=200,\n",
    "    token_counter=llm,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on='human',\n",
    ")\n",
    "\n",
    "def simple_node(state: Mystate):\n",
    "    # 체인상 기존 메시지를 정리하고 프롬프트에 넣는게 맞다\n",
    "    print(f'정리 전 메시지 개수: {len(state['messages'])}개')\n",
    "    trimmed_messages = trimmer.invoke(state['messages'])\n",
    "    print(f'정리 후 메시지 개수: {len(trimmed_messages)}개')\n",
    "    \n",
    "    state['messages'] = trimmed_messages\n",
    "    chain = prompt_template | llm\n",
    "    res = chain.invoke(state)\n",
    "    \n",
    "    return {'messages': res}\n",
    "\n",
    "builder.add_node('simple_node', simple_node)\n",
    "builder.add_edge(START, 'simple_node')\n",
    "builder.add_edge('simple_node', END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "740c30d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정리 전 메시지 개수: 11개\n",
      "정리 후 메시지 개수: 3개\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "안녕\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "안녕하세요! 어떻게 도와드릴까요?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "슬슬 점심시간인데, 뭘 먹는게 좋을까?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "점심시간이라니 좋네요! 어떤 걸 좋아하시나요? 가벼운 샐러드나 샌드위치, 아니면 따뜻한 국이나 찌개 같은 것도 괜찮을 것 같아요. 혹은 국물이 시원한 냉면이나 쫄깃한 비빔밥도 좋아요. 시간과 장소, 그리고 기분에 따라 적절한 메뉴를 골라보면 더 좋을 것 같아요. 특별히 선호하는 음식이나 오늘의 컨디션에 맞춰 추천이 필요하시면 알려주세요!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "지금 좀 피곤하고, 졸린 상태야\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "그렇다면 오늘은 가볍고 속 편한 음식을 추천드릴게요. 피곤하고 졸릴 때는 소화가 잘 되고 몸에 부담이 적은 음식이 좋아요. 예를 들어, 미소된장국이나 따뜻한 죽(예: 콩죽이나 곡물죽), 또는 가벼운 샌드위치나 토스트도 좋아요. 차 한잔이나 따뜻한 차와 함께 먹으면 기분도 좋아지고 몸도 편안해질 거예요. 조금 휴식을 취하면서 에너지를 충전하는 것도 중요하니, 느긋하게 드시길 권해드려요!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "그럼 메뉴를 리스트로 만들어줘\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "물론이죠! 피곤하고 졸릴 때 먹기 좋은 메뉴 리스트를 만들어 드릴게요.\n",
      "\n",
      "### 피로할 때 추천 메뉴 리스트\n",
      "\n",
      "1. 미소된장국  \n",
      "2. 따뜻한 죽 (콩죽, 곡물죽, 야채죽 등)  \n",
      "3. 부드러운 계란찜  \n",
      "4. 오트밀 또는 곡물 시리얼 + 따뜻한 우유  \n",
      "5. 가벼운 샌드위치 (단백질과 채소 포함)  \n",
      "6. 토스트와 과일 (바나나, 사과 등)  \n",
      "7. 따뜻한 차(녹차, 생강차, 허브티 등)와 함께 가벼운 간식  \n",
      "\n",
      "이 중에서 마음에 드는 메뉴를 골라보세요! 몸과 마음이 조금 더 편안해지길 바랄게요.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "어제 게임을 너무 많이 해서 피곤한걸까\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "네, 어제 게임을 너무 많이 해서 피곤할 수 있어요. 오래 앉아 있거나 집중해서 하는 활동은 몸과 마음을 피로하게 만들 수 있거든요. 충분한 휴식을 취하고 수분을 섭취하며, 몸을 풀거나 산책을 하는 것도 도움이 될 수 있어요. 만약 계속 피곤하거나 몸이 무겁다면, 휴식을 더 충분히 가지거나 수면을 충분히 취하는 것이 좋겠어요.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "아까 점심 메뉴 추천해준거 뭐였지?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "죄송하지만, 지금까지의 대화 기록에는 점심 메뉴 추천 내용이 포함되지 않아서 어떤 메뉴를 추천했는지 확인할 수 없어요. 혹시 특별히 원하는 음식 종류나 가고 싶은 곳이 있다면 알려주시면 새로운 추천을 도와드릴게요!\n"
     ]
    }
   ],
   "source": [
    "config = {'configurable': {'thread_id': 'asdf5678'}}\n",
    "\n",
    "state = {\n",
    "    'messages': [HumanMessage(content='아까 점심 메뉴 추천해준거 뭐였지?')],\n",
    "    'lang': 'korean'\n",
    "}\n",
    "\n",
    "res = graph.invoke(state, config)\n",
    "\n",
    "for msg in res['messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36451fb2",
   "metadata": {},
   "source": [
    "## 스트리밍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0539bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mystate(MessagesState):\n",
    "    lang: str\n",
    "\n",
    "builder = StateGraph(state_schema=Mystate)\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', '너는 유능한 어시스턴트야. 너의 능력을 최대한 활용해서 답을 해봐. {lang}언어로 답해.'),\n",
    "    MessagesPlaceholder(variable_name='messages'),\n",
    "])\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    strategy='last',\n",
    "    max_tokens=200,\n",
    "    token_counter=llm,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on='human',\n",
    ")\n",
    "\n",
    "def simple_node(state: Mystate):\n",
    "    trimmed_messages = trimmer.invoke(state['messages'])    \n",
    "    state['messages'] = trimmed_messages\n",
    "    chain = prompt_template | llm\n",
    "    res = chain.invoke(state)\n",
    "    return {'messages': res}\n",
    "\n",
    "builder.add_node('simple_node', simple_node)\n",
    "builder.add_edge(START, 'simple_node')\n",
    "builder.add_edge('simple_node', END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "763b92d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|신|라|면|과| 너|구|리| 둘| 다| 인기| 많은| 라|면|이|지만|,| 어떤| 게| 더| 맛|있|다고| 단|정|짓|기| 어려|워|요|.| 각각|의| 특징|이| 있어서| 개인| 취|향|에| 따라| 다|를| 수| 있|거|든|요|.\n",
      "\n",
      "|-| **|신|라|면|**|:| 매|콤|하고| 진|한| 국|물| 맛|이| 특징|으로|,| 매|운| 음|식을| 좋아|하는| 사람|들에게| 인|기가| 많|아요|.| 국|물|의| 깊|이|와| 풍|미|가| 좋아|서| 많은| 사람들이| 즐|겨| 먹|어요|.\n",
      "|-| **|너|구|리|**|:| 해|물|과| 깔|끔|한| 맛|이| 나는| 국|물|로|,| 좀| 더| 담|백|하고| 부|드|러운| 맛|을| 좋아|하는| 분|들에게| 좋아|요|.| 특히|,| 간|이| 적|당|해서| 많은| 사람들이| 부담| 없이| 즐|기|기| 좋아|요|.\n",
      "\n",
      "|결|국|,| 어떤| 맛|이| 더| 좋은|지는| 개인| 취|향|에| 따라| 다|르|니|,| 혹|시| 조금| 매|운| 것을| 좋아|한다|면| 신|라|면|,| 깔|끔|하고| 부|드|러운| 맛|을| 원|한다|면| 너|구|리를| 추천|드|려|요|!| 직접| 한| 번|씩| 먹|어|보|는| 것도| 좋은| 방법|일| 것| 같|아요|.||"
     ]
    }
   ],
   "source": [
    "config = {'configurable': {'thread_id': 'zxcv333'}}\n",
    "\n",
    "state = {\n",
    "    'messages': [HumanMessage(content='신라면이랑 너구리 중에 뭐가 더 맛있을까?')],\n",
    "    'lang': '한국어'\n",
    "}\n",
    "\n",
    "for chunk, metadata in graph.stream(state, config=config, stream_mode='messages'):\n",
    "    print(chunk.content, end='|')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
