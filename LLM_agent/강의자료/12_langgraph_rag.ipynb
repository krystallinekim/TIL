{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13629a95",
   "metadata": {},
   "source": [
    "# RAG w/ Langgraph\n",
    "랭그래프에 RAG 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "775e4f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c3eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# RAG 준비\n",
    "\n",
    "# 1. Loader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from bs4.filter import SoupStrainer\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=('https://lilianweng.github.io/posts/2023-06-23-agent/',),  # 여러개 가져오려면 튜플 안에 추가하면 됨\n",
    "    # 웹페이지에서 필요한 정보를 선택하기\n",
    "    bs_kwargs={\n",
    "        'parse_only': SoupStrainer(class_=['post-content'])\n",
    "    },\n",
    "    # header_template={},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# 웹페이지를 그대로 긁어오면, 필요없는 부분(사이트 제목, 밑에 광고들, 등등)이 뒤섞여서 나온다. -> 필요한 부분을 선택적으로 가져와야 함 -> bs_kwargs\n",
    "# from pprint import pprint\n",
    "# pprint(docs[0].page_content)\n",
    "\n",
    "# 2. Splitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=500\n",
    ")\n",
    "splitted_docs = splitter.split_documents(docs)\n",
    "# print(len(splitted_docs))\n",
    "\n",
    "# 3. Enbedding Model\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-small')  # small <-> large\n",
    "\n",
    "# 4. Vectorstore (일단은 FAISS, 나중엔 클라우드(Pinecone)에 저장할 것)\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(splitted_docs, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28570f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m \n",
      "Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "# 프롬프트\n",
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull('rlm/rag-prompt')\n",
    "for msg in prompt.messages:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9eb3b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 랭그래프\n",
    "\n",
    "# 1. State\n",
    "from typing_extensions import TypedDict, List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class State(TypedDict):\n",
    "    # 프롬프트에 뚫린 구멍은 반드시 채워줘야함\n",
    "    question: str  # 사용자의 질문\n",
    "    context: List[Document]  # LLM에게 전달할 RAG 데이터의 문서조각. List[Document]는 context에 Document 객체가 리스트로 모여있을 것이라는 의미\n",
    "    answer: str  # LLM의 답안\n",
    "\n",
    "# 2. Node\n",
    "# 2-1. 검색노드\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vectorstore.similarity_search(state['question'], k=4)  # [Document 타입 객체 x 4]\n",
    "    return {'context': retrieved_docs}  # 언급하지 않은 state 항목들(question, answer)은 내부적으로 알아서 그대로 들어가짐\n",
    "\n",
    "# 2-2. 답변생성노드\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def generate(state: State):\n",
    "\n",
    "    # 내용에 해당하는 page_content만 모아서 토큰 절약\n",
    "    context_str = ''\n",
    "    for doc in state['context']:\n",
    "        context_str += doc.page_content + '\\n-----------------------------------------------\\n'\n",
    "\n",
    "    question_with_context = prompt.invoke({'question': state['question'], 'context': context_str})\n",
    "    llm = ChatOpenAI(model='gpt-4.1', temperature=0)\n",
    "    res = llm.invoke(question_with_context)    \n",
    "    return {'answer': res.content}\n",
    "\n",
    "# 3. Graph\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node('retrieve', retrieve)\n",
    "builder.add_node('generate', generate)\n",
    "\n",
    "builder.add_edge(START, 'retrieve')\n",
    "builder.add_edge('retrieve', 'generate')\n",
    "builder.add_edge('generate', END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# 4. 시각화\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb763236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에이전트 시스템은 주어진 목표를 달성하기 위해 자율적으로 작업을 수행하는 소프트웨어 구조입니다. LLM(대형 언어 모델) 기반 에이전트 시스템은 인터넷 검색, 장기 기억 관리, 파일 출력, 외부 API 호출 등 다양한 도구를 활용해 복잡한 문제를 해결할 수 있습니다. 또한, 자신의 행동을 지속적으로 평가하고 효율적으로 작업을 수행하도록 설계되어 있습니다.\n"
     ]
    }
   ],
   "source": [
    "final_state = graph.invoke({'question': '에이전트 시스템에 대해 알려줘'}) \n",
    "\n",
    "print(final_state['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65d78ea",
   "metadata": {},
   "source": [
    "## RAG +a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e51979c",
   "metadata": {},
   "source": [
    "### 메타데이터 편집\n",
    "원본 내용은 그대로 두되, 추가적으로 넣고 싶은 내용을 추가/삭제할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3bb3e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'beginning'}\n"
     ]
    }
   ],
   "source": [
    "# splitted_docs를 나눠서 전/중/후반부를 메타데이터에 추가하고 싶음\n",
    "third = len(splitted_docs) // 3\n",
    "\n",
    "for idx, doc in enumerate(splitted_docs):\n",
    "    if idx < third:\n",
    "        doc.metadata['section'] = 'beginning'\n",
    "    elif idx < third * 2:\n",
    "        doc.metadata['section'] = 'middle'        \n",
    "    else:\n",
    "        doc.metadata['section'] = 'end'\n",
    "print(splitted_docs[0].metadata)\n",
    "\n",
    "vectorstore = FAISS.from_documents(splitted_docs, embedding=embedding) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae657ab9",
   "metadata": {},
   "source": [
    "### 쿼리 분석/개선\n",
    "\n",
    "질문이 이어질 때, 이전 질문 내용을 사용해야 하는 질문이 들어오는 경우가 있다.\n",
    "\n",
    "지금 질문 + 이전 질문 내용과 답변 내용을 LLM에 넣어서, 새로 적합한 쿼리를 만들어서 RAG를 돌려줘야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e275901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쿼리를 분석해서, 질문에 전/중/후반부가 있다면 메타데이터를 참고하면 좋겠음\n",
    "from typing import Literal  # 말 그대로\n",
    "from typing_extensions import Annotated  # 첨언, 주석\n",
    "\n",
    "\n",
    "# StructuredOutput에서 사용하기 좋다. pydantic이랑 비슷한거\n",
    "class Search(TypedDict):\n",
    "    '''Vectorstore Search Query'''\n",
    "    # Annotated[타입(str), NOT NULL(... : 비어있지 않다), 설명(이 항목에 대한 설명)]\n",
    "    query: Annotated[str, ..., 'search query to run']\n",
    "    section: Annotated[\n",
    "        Literal['beginning', 'middle', 'end'],  # section은 전/중/후반부만 존재함\n",
    "        ...,\n",
    "        'Section to query'\n",
    "    ]\n",
    "    \n",
    "# question / query: question보다 좀 더 유사도 검색이 잘 되게 하는 query가 필요함\n",
    "class MyState(TypedDict):\n",
    "    question: str  \n",
    "    query: Search  # 이 쿼리는 Search를 참고할 것 -> state를 더 자세하게 정의하기 위해 따로 정의한 class Search\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b19f765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'LLM 작업 분해', 'section': 'beginning'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model='gpt-4.1', temperature=0)\n",
    "\n",
    "s_llm = llm.with_structured_output(Search)  # 답변이 무조건 Search 클래스의 인스턴스로 나온다\n",
    "s_llm.invoke('그그 문서 앞쪽에 LLM 작ㅇ업 분해인가 하는 그게 뭐야')  # 벡터스토어에 비교하기 훨씬 좋게 맞춰준다. 기준은 Search 클래스의 docstring에 써있는 그대로."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dc933a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_query(state: MyState):\n",
    "    # Search 클래스에 맞게 사용자의 question을 {query, section}으로 바꿔줌\n",
    "    s_llm = llm.with_structured_output(Search)  # 답변이 무조건 Search 클래스의 인스턴스로 나온다\n",
    "    query = s_llm.invoke(state['question'])\n",
    "    return {'query': query}\n",
    "\n",
    "def retrieve(state: MyState):\n",
    "    query = state['query']\n",
    "    retrieved_docs = vectorstore.similarity_search(\n",
    "        query['query'], \n",
    "        # 필터함수를 돌려서 section이 쿼리의 section과 맞을 경우만 추려냄\n",
    "        filter=lambda metadata: metadata.get('section') == query['section']  # 벡터스토어의 결과에도 검증함수를 걸 수 있고, 그냥 데이터만이 아니라 메타데이터도 조건에 걸 수 있다. \n",
    "    )\n",
    "    return {'context': retrieved_docs}  # 언급하지 않은 state 항목들(question, answer)은 내부적으로 알아서 그대로 들어가짐\n",
    "\n",
    "def generate(state: MyState):\n",
    "    context_str = ''\n",
    "    for doc in state['context']:\n",
    "        context_str += doc.page_content + '\\n-----------------------------------------------\\n'\n",
    "\n",
    "    question_with_context = prompt.invoke({'question': state['question'], 'context': context_str})\n",
    "    res = llm.invoke(question_with_context)    \n",
    "    return {'answer': res.content}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node('analyze_query', analyze_query)\n",
    "builder.add_node('retrieve', retrieve)\n",
    "builder.add_node('generate', generate)\n",
    "\n",
    "builder.add_edge(START, 'analyze_query')\n",
    "builder.add_edge('analyze_query', 'retrieve')\n",
    "builder.add_edge('retrieve', 'generate')\n",
    "builder.add_edge('generate', END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1335f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '그그 문서 앞쪽에 LLM 작ㅇ업 분배인가 하는 그게 뭐야',\n",
       " 'context': [Document(id='f2ca9a03-24d9-4c81-a689-e278866313a7', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'beginning'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'),\n",
       "  Document(id='c9cb0a4e-36d4-4e16-9ea7-387eb87243cb', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'beginning'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'),\n",
       "  Document(id='36e87ee7-a951-4133-823f-42e0f54f3340', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'beginning'}, page_content='MRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of “expert” modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.'),\n",
       "  Document(id='fdd0abb2-9f89-4091-abd4-5c143d6e3752', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'beginning'}, page_content='Tool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.')],\n",
       " 'answer': '문서 앞쪽에 나오는 \"LLM 작업 분배\"는 LLM(대형 언어 모델)이 큰 작업을 더 작은 하위 목표나 단계로 쪼개어(subgoal and decomposition) 효율적으로 처리하는 과정을 의미합니다. 즉, 복잡한 문제를 해결하기 위해 LLM이 스스로 작업을 분해하고 각 단계별로 처리하는 역할을 한다는 뜻입니다. 이를 통해 LLM 기반 에이전트가 복잡한 문제도 체계적으로 해결할 수 있습니다.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({'question': '그그 문서 앞쪽에 LLM 작ㅇ업 분배인가 하는 그게 뭐야'})  # 메타데이터를 'beginning' 만 가져온 걸 알 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b5013d",
   "metadata": {},
   "source": [
    "## 대화형 RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0e08d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from bs4.filter import SoupStrainer\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=('https://lilianweng.github.io/posts/2023-06-23-agent/',),\n",
    "    bs_kwargs={\n",
    "        'parse_only': SoupStrainer(class_=['post-content'])\n",
    "    },\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=500\n",
    ")\n",
    "splitted_docs = splitter.split_documents(docs)\n",
    "\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "vectorstore = FAISS.from_documents(splitted_docs, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a822af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Source: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}\\nContent: \"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease\\n\\nSource: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}\\nContent: You will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code’s language, and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the “entrypoint” file, then go to the ones that are imported by that file, and so on.\\n\\nSource: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}\\nContent: Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.',\n",
       " [Document(id='c0874da3-abac-4330-bd77-269db33ae6a0', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='\"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease'),\n",
       "  Document(id='9211d521-1083-44ae-b481-646e8ce3c93a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='You will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code’s language, and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the “entrypoint” file, then go to the ones that are imported by that file, and so on.'),\n",
       "  Document(id='d2488af9-06ba-4a3a-9c1c-63c43f9d8884', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# RAG는 노드가 아니라 툴 -> 쿼리를 받고, 결과물을 반납함\n",
    "@tool(response_format='content_and_artifact')  # LLM이 결과물 2개가 들어온 걸 인지하게 된다\n",
    "def retrieve(query: str):\n",
    "    # 그래서 설명이 필요함\n",
    "    '''\n",
    "    Retrieve information related to a query. \n",
    "    Args: \n",
    "        query: Query to search\n",
    "    '''\n",
    "    # 원본 텍스트(Artifact)\n",
    "    docs = vectorstore.similarity_search(query, k=3)\n",
    "    # 편집한 텍스트(Content)\n",
    "    result_text = '\\n\\n'.join(\n",
    "        (f'Source: {doc.metadata}\\nContent: {doc.page_content}')\n",
    "        for doc in docs\n",
    "    )\n",
    "    return result_text, docs  # 편집한 텍스트와 원본 텍스트를 동시에 내보냄\n",
    "\n",
    "retrieve.invoke('에이전트에 대해 설명해 줘')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83480664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4.1', temperature=0)\n",
    "\n",
    "def query_or_respond(state: MessagesState):\n",
    "    '''1. 도구 호출을 하거나, 2. 최종 응답을 한다.'''\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    res = llm_with_tools.invoke(state['messages'])\n",
    "    return {'messages': [res]}  # 결과로 나온 AImsg를 알아서 합치는 문법 -> 기존 메시지는 유지하면서 새로나온 메시지를 추가해줌\n",
    "\n",
    "tools = ToolNode([retrieve])  # 툴박스 노드\n",
    "\n",
    "def generate(state: MessagesState):\n",
    "    '''지금 필요한 툴 메시지들을 보고, 응답을 생성해줌'''\n",
    "    tool_messages = []  # System, Human, AI message 이외에 Tool message가 따로 있고, 그걸 모은 결과\n",
    "    for msg in reversed(state['messages']):  # 기록상 앞쪽에 오래된 게 오므로 최신메시지부터 순회하기 위해 뒤집음\n",
    "        if msg.type == 'tool':\n",
    "            tool_messages.append(msg)\n",
    "        else:\n",
    "            break  # 가장 최신의 tool msg들을(여러개일 수 있다) 모아오겠다는 것\n",
    "    tool_messages.reverse()  # 다시 뒤집어서 시간순서로 바꿔줌\n",
    "    \n",
    "    docs_content = '\\n\\n'.join(doc.content for doc in tool_messages)\n",
    "\n",
    "    # 툴 메시지는 여기에 들어감(있다면)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks.\"\n",
    "        \"Use the following pieces of retrieved context to answer the question.\"\n",
    "        \"If you don't know the answer, say that you don't know.\"\n",
    "        \"Use three sentences maximum and keep the answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    \n",
    "    # 이미 넣은(혹은 없는) Tool 메시지를 제외하고, AI, Human, System 메시지만 모아서 정리함\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")  # human, system은 전부 모으고\n",
    "        or (message.type == \"ai\" and not message.tool_calls)  # AI메시지중에 tool 결과물이 아닌 것만 모음\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages  # 시스템 메시지 + 지금까지의 대화 메시지 중 중요한 내용을 프롬프트에 넣음\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62eaa434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.graph import START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node('query_or_respond', query_or_respond)\n",
    "# builder.add_node(query_or_respond)  # 이렇게 쓰는것도 가능함\n",
    "builder.add_node('tools', tools)\n",
    "builder.add_node('generate', generate)\n",
    "\n",
    "# builder.set_entry_point('query_or_respond')\n",
    "builder.add_edge(START, 'query_or_respond')\n",
    "builder.add_conditional_edges(\n",
    "    'query_or_respond',\n",
    "    tools_condition,  # path - 조건에 따라 라우팅을 보냄 \n",
    "    {END: END, 'tools': 'tools'}  # 정확하게 다음 노드를 지정할 수 있다. tools를 쓰지 않으면 END로, tools를 써야되면 tools로\n",
    ")\n",
    "builder.add_edge('tools', 'generate')\n",
    "# builder.set_finish_point('generate')\n",
    "builder.add_edge('generate', END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72823418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "문서에서 에이전트에 대해 뭐라고 설명하고 있니?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_Lfc6cHqCgqo8ZEWspDdJHUKm)\n",
      " Call ID: call_Lfc6cHqCgqo8ZEWspDdJHUKm\n",
      "  Args:\n",
      "    query: 문서에서 에이전트에 대한 설명\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "('Source: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}\\nContent: GPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n\\nSource: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}\\nContent: is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython toolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"\\n\\nSource: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}\\nContent: note that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a', [Document(id='660966cf-5fac-434b-a1a5-b0286b331f8e', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='GPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",'), Document(id='a1f96bab-e864-43a8-be63-a4b0605e3ed1', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython toolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"'), Document(id='586ac342-eab3-463b-9282-8fb6b000046a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='note that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a')])\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "문서에서는 에이전트를, 자연어로 주어진 작업을 코드 저장소 전체로 구현하는 프로젝트(GPT-Engineer)에서, 작업을 더 작은 구성 요소로 나누고 필요시 사용자에게 질문하여 명확히 하는 역할로 설명하고 있습니다. 에이전트는 지시를 읽고 바로 실행하지 않으며, 먼저 명확히 해야 할 부분을 요약하고, 하나의 명확화 질문을 선택해 사용자 답변을 기다립니다. 즉, 에이전트는 작업 명확화와 세분화, 사용자와의 상호작용을 통해 개발을 진행하는 역할을 합니다.\n"
     ]
    }
   ],
   "source": [
    "input_state = {\n",
    "    'messages': [\n",
    "        {'role': 'user', 'content': '문서에서 에이전트에 대해 뭐라고 설명하고 있니?'}\n",
    "    ]\n",
    "}\n",
    "\n",
    "res = graph.invoke(input_state)\n",
    "\n",
    "for msg in res['messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bf5a62",
   "metadata": {},
   "source": [
    "### 벡터스토어 대체(클라우드에)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4cf3d699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pinecone\n",
    "import os \n",
    "from pinecone import Pinecone\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974f0864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x258fd873cb0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이제 이 작업은 더이상 할 필요가 없어졌다\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from bs4.filter import SoupStrainer\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore \n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=('https://lilianweng.github.io/posts/2023-06-23-agent/',),\n",
    "    bs_kwargs={\n",
    "        'parse_only': SoupStrainer(class_=['post-content'])\n",
    "    },\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=500\n",
    ")\n",
    "splitted_docs = splitter.split_documents(docs)\n",
    "\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "\n",
    "pc = Pinecone()\n",
    "\n",
    "index_name = 'gaida-1st'\n",
    "# PineconeVectorStore.from_documents(\n",
    "#     splitted_docs, \n",
    "#     index_name=index_name, \n",
    "#     embedding=embedding\n",
    "# )  # 실행될 때마다 데이터가 들어가서 영구저장된다. 두번 실행하면 똑같은게 두번 들어감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c851ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어 불러오기 - 클라우드처럼 어디나에서 사용 가능. 대신 오래걸린다 -> 많이 쓰는 데이터를 캐싱해서 메모리에 올린다던가 해서 속도 개선 가능\n",
    "vectorstore = PineconeVectorStore.from_existing_index(index_name=index_name, embedding=embedding)  # 기존 저장된 인덱스를 불러온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82f51660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "문서에서 에이전트에 대해 뭐라고 설명하고 있니?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_Y9qvCGwtnRtQJJXEN2ngD07w)\n",
      " Call ID: call_Y9qvCGwtnRtQJJXEN2ngD07w\n",
      "  Args:\n",
      "    query: 문서에서 에이전트에 대한 설명\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "('Source: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}\\nContent: GPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n\\nSource: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}\\nContent: is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython toolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"\\n\\nSource: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}\\nContent: note that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a', [Document(id='660966cf-5fac-434b-a1a5-b0286b331f8e', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='GPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",'), Document(id='a1f96bab-e864-43a8-be63-a4b0605e3ed1', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython toolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"'), Document(id='586ac342-eab3-463b-9282-8fb6b000046a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='note that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a')])\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "문서에서는 에이전트를, 자연어로 주어진 작업을 코드 저장소 전체로 구현하는 프로젝트(GPT-Engineer)에서, 작업을 더 작은 구성 요소로 나누고 필요한 경우 사용자에게 질문하여 명확히 하는 역할로 설명하고 있습니다. 에이전트는 지시를 읽고 바로 실행하지 않으며, 먼저 명확히 해야 할 부분을 요약하고, 하나의 명확화 질문을 선택해 사용자에게 답변을 기다립니다. 즉, 에이전트는 작업 명확화와 세분화, 사용자와의 상호작용을 통해 효율적인 코드 생성을 돕는 역할을 합니다.\n"
     ]
    }
   ],
   "source": [
    "input_state = {\n",
    "    'messages': [\n",
    "        {'role': 'user', 'content': '문서에서 에이전트에 대해 뭐라고 설명하고 있니?'}\n",
    "    ]\n",
    "}\n",
    "\n",
    "res = graph.invoke(input_state)\n",
    "\n",
    "for msg in res['messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5b9ec0",
   "metadata": {},
   "source": [
    "### 대화 기록 저장하기(Langgraph Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc2575df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed2ead50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "안녕?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "안녕하세요! 무엇을 도와드릴까요? 😊\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "task decomposition에 대해 설명해봐\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "네, \"task decomposition\"에 대해 설명드리겠습니다.\n",
      "\n",
      "**Task Decomposition(작업 분해)**란, 큰 작업이나 문제를 더 작고 관리하기 쉬운 하위 작업(subtasks)으로 나누는 과정을 말합니다. 이 방법은 복잡한 문제를 해결하거나 프로젝트를 효율적으로 관리할 때 매우 유용하게 사용됩니다.\n",
      "\n",
      "### 주요 목적\n",
      "- **복잡성 감소:** 큰 문제를 작은 단위로 나누면 각 부분을 더 쉽게 이해하고 처리할 수 있습니다.\n",
      "- **효율성 향상:** 여러 사람이 동시에 하위 작업을 맡아 병렬적으로 진행할 수 있습니다.\n",
      "- **진행 상황 추적:** 각 하위 작업의 완료 여부를 확인하면서 전체 진행 상황을 쉽게 파악할 수 있습니다.\n",
      "\n",
      "### 예시\n",
      "1. **소프트웨어 개발:**  \n",
      "   \"웹사이트 만들기\"라는 큰 작업을  \n",
      "   - 디자인\n",
      "   - 프론트엔드 개발\n",
      "   - 백엔드 개발\n",
      "   - 테스트  \n",
      "   등으로 나눌 수 있습니다.\n",
      "\n",
      "2. **논문 작성:**  \n",
      "   \"논문 작성\"이라는 작업을  \n",
      "   - 자료 조사\n",
      "   - 초안 작성\n",
      "   - 수정 및 교정\n",
      "   - 참고문헌 정리  \n",
      "   등으로 분해할 수 있습니다.\n",
      "\n",
      "### 적용 분야\n",
      "- 프로젝트 관리\n",
      "- 인공지능(특히, 자동화된 문제 해결)\n",
      "- 교육 및 학습\n",
      "- 일상적인 문제 해결 등\n",
      "\n",
      "### 요약\n",
      "Task decomposition은 큰 문제를 작은 단위로 쪼개어 효율적으로 해결하는 전략입니다. 이를 통해 복잡한 작업도 체계적으로 접근할 수 있습니다.\n",
      "\n",
      "더 궁금한 점이 있으신가요? 예시나 실제 적용 방법이 궁금하시면 말씀해 주세요!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "문서에서는 뭐라고 했는데?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_q8tSjnwf8uf88cLahBLUT7fm)\n",
      " Call ID: call_q8tSjnwf8uf88cLahBLUT7fm\n",
      "  Args:\n",
      "    query: task decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "('Source: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}\\nContent: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\n\\nSource: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}\\nContent: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\n\\nSource: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}\\nContent: Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.', [Document(id='e53047d1-52ff-4d16-81c2-992a40fcabe2', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'), Document(id='26610e3e-bb99-408c-b6e1-f7e61c7b5d6b', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='ae1a0434-b8cc-4d04-bb64-6a1ea18cd12e', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.')])\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "문서에서는 task decomposition(작업 분해)을 다음과 같이 설명하고 있습니다.  \n",
      "1) LLM(대형 언어 모델)이 간단한 프롬프트(예: \"Steps for XYZ.\", \"What are the subgoals for achieving XYZ?\")로 작업을 분해할 수 있고,  \n",
      "2) 작업별로 구체적인 지시(예: \"Write a story outline.\")를 사용하거나,  \n",
      "3) 인간의 입력을 통해서도 작업 분해가 가능하다고 합니다.  \n",
      "또한, Chain of Thought(CoT) 기법처럼 \"step by step\"으로 생각하게 하여 복잡한 작업을 더 작고 단순한 단계로 나누는 방법도 소개하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'configurable': {'thread_id': 'abc123'}\n",
    "}\n",
    "\n",
    "input_state = {\n",
    "    'messages': [\n",
    "        {'role': 'user', 'content': '문서에서는 뭐라고 했는데?'}\n",
    "    ]\n",
    "}\n",
    "\n",
    "res = graph.invoke(input_state, config)\n",
    "\n",
    "for msg in res['messages']:\n",
    "    msg.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
