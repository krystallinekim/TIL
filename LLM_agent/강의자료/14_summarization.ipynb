{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33b0c654",
   "metadata": {},
   "source": [
    "# **요약(Summarization)**\n",
    "\n",
    "매우 많은 양의 문서(context)가 있을 경우, 요약하는 방법\n",
    "1. 프롬프트에 전부 때려박기 -> LLM아 알아서 요약해줘 => 문서 양이 context window를 넘어가면 사용 불가\n",
    "2. Map-Reduce: 각 문서를 요약하고(LLM이) 합쳐서 최종 요약본을 만들기(LLM이)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7e5422a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17d6a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader\n",
    "\n",
    "loader = ArxivLoader(\n",
    "    query='reasoning',\n",
    ")\n",
    "\n",
    "docs = loader.load()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24e3dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4.1', temperature=0)\n",
    "# llm = init_chat_model(model='gpt-4o',model_provider='openai', temperature=0)  # 같은 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9b2288",
   "metadata": {},
   "source": [
    "## Stuff Docs(때려박기)\n",
    "\n",
    "지금 모델에서 논문 2편까지는 어떻게 모델에 때려박는게 가능하지만, 3편부터는 제한에 걸려서 처리가 불가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0b31168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '아래 내용을 정확하게 요약해 줘. \\n\\n{context}')\n",
    "])\n",
    "\n",
    "chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "res = chain.invoke({'context': docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1edd604f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아래 두 논문의 핵심 내용을 각각 정확하게 요약합니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Process or Result? Manipulated Ending Tokens Can Mislead Reasoning LLMs to Ignore the Correct Reasoning Steps**\n",
      "\n",
      "**핵심 요약:**\n",
      "\n",
      "- **연구 목적:**  \n",
      "  최근 수리 추론(Chain-of-Thought, CoT) 능력이 향상된 대형 언어모델(LLM)들이 입력된 추론 과정(Reasoning Tokens)에 미세한 오류가 포함될 때 얼마나 취약한지 분석함.\n",
      "\n",
      "- **주요 발견:**  \n",
      "  - **Compromising Thought (CPT) 현상:**  \n",
      "    추론 과정의 마지막 계산 결과(ending tokens)만 살짝 조작해도, LLM들은 올바른 추론 과정을 무시하고 조작된(잘못된) 결과를 최종 답으로 채택하는 경향이 강함.\n",
      "  - **자기 교정(Self-correction) 한계:**  \n",
      "    LLM이 스스로 계산을 정확히 할 수 있음에도, 입력된 조작된 reasoning tokens에 쉽게 영향을 받아 자기 교정 능력이 크게 저하됨.\n",
      "  - **구조 vs. 내용:**  \n",
      "    기존 연구와 달리, reasoning chain의 구조적 변화보다 마지막 결과값(ending token)의 국소적 조작이 모델의 추론 결과에 더 큰 영향을 미침.\n",
      "  - **보안 취약점:**  \n",
      "    DeepSeek-R1 모델은 조작된 reasoning tokens가 입력되면 아예 추론을 중단(답을 내지 않음)하는 현상도 발견됨.\n",
      "\n",
      "- **실험 방법:**  \n",
      "  - 여러 LLM(DeepSeek-R1, OpenAI-o1, o3-mini 등)에 대해, ending token을 한 자리만 바꾸는 등 미세하게 조작한 reasoning tokens를 입력하고, 모델이 이를 얼마나 잘 감지/교정하는지 평가.\n",
      "  - CPT 저항성을 높이기 위한 3가지 프롬프트(불확실성 유도, 오류 명시, 출력 prefix 강제)를 실험.\n",
      "\n",
      "- **결론 및 시사점:**  \n",
      "  - 현재의 reasoning LLM들은 미세한 결과값 조작에 매우 취약하며, 자기 교정 능력이 쉽게 무력화됨.\n",
      "  - 수리 추론 등 reasoning이 중요한 응용에서 신뢰성과 보안에 각별한 주의가 필요함.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **Hypothesis Testing Prompting Improves Deductive Reasoning in Large Language Models**\n",
      "\n",
      "**핵심 요약:**\n",
      "\n",
      "- **연구 목적:**  \n",
      "  기존 Chain-of-Thought(CoT) 프롬프트 방식이 복잡한 논리/연역 추론에서 한계(비합리적 추론, 허구적 경로 등)를 보임에 따라, 이를 개선할 새로운 프롬프트 기법을 제안함.\n",
      "\n",
      "- **제안 방법:**  \n",
      "  - **Hypothesis Testing Prompting:**  \n",
      "    결론에 대한 가설(참/거짓)을 세우고, 역방향 추론 및 사실 검증을 통해 결론의 타당성을 단계별로 확인하는 프롬프트 구조를 도입.\n",
      "    - 예: \"먼저 결론이 참이라고 가정하고, 필요한 조건을 역추적하여 검증. 다음으로 결론이 거짓이라고 가정하고, 필요한 조건을 검증. 두 경우 모두 만족하지 않으면 'Unknown'으로 판단.\"\n",
      "  - 이 방식은 단순히 추론 과정을 나열하는 CoT보다, 추론의 목적·출발점·효과성까지 고려함.\n",
      "\n",
      "- **실험 및 결과:**  \n",
      "  - 두 논리 추론 데이터셋(RuleTaker, ProofWriter)에서 실험.\n",
      "  - 기존 Standard Prompting, CoT Prompting 대비, Hypothesis Testing Prompting이 특히 복잡한(다단계) 추론에서 정확도가 크게 향상됨.\n",
      "  - ProofWriter의 'Unknown' 레이블(불확실성 판단)에서도 CoT 대비 두 배 이상의 정확도 향상.\n",
      "  - 사람이 평가한 중간 추론 과정의 합리성도 Hypothesis Testing Prompting이 월등히 높음.\n",
      "\n",
      "- **결론 및 시사점:**  \n",
      "  - Hypothesis Testing Prompting은 LLM의 연역적 추론 능력과 추론 과정의 합리성을 모두 크게 개선함.\n",
      "  - 다양한 reasoning task에서 LLM의 신뢰성과 해석 가능성을 높이는 효과적인 프롬프트 설계 전략임을 시사.\n",
      "\n",
      "---\n",
      "\n",
      "**요약 비교:**  \n",
      "- 첫 논문은 LLM의 reasoning 과정이 미세한 결과값 조작에 매우 취약함을 밝히고, 구조적 변화보다 결과값 조작이 더 치명적임을 실증함.\n",
      "- 두 번째 논문은 기존 CoT의 한계를 극복하기 위해, 가설 검증 기반의 프롬프트 설계가 LLM의 연역 추론 능력과 과정의 합리성을 크게 높인다는 점을 실험적으로 증명함.\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeda397e",
   "metadata": {},
   "source": [
    "## Map - Reduce\n",
    "\n",
    "list(map(int, '12345'))처럼, 문서를 나눠서 각각 요약한다는 뜻\n",
    "\n",
    "map(reduce, [doc1, doc2, doc3])\n",
    "\n",
    "1. 문서를 나눔\n",
    "2. 나눈 문서를 각각 요약\n",
    "3. 요약본을 합침\n",
    "4. 다시 요약\n",
    "\n",
    "여기서부터는 랭그래프가 필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fbf8de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '아래 내용을 정확하게 요약해 줘. \\n\\n{context}')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45fdf9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_template = '''\n",
    "이건 요약된 문서들이야.\n",
    "---\n",
    "{docs}\n",
    "---\n",
    "이 문서들을 취합해서 최종 통합본을 만들어 줘\n",
    "'''\n",
    "\n",
    "reduce_prompt = ChatPromptTemplate([\n",
    "    ('human', reduce_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9ab871",
   "metadata": {},
   "source": [
    "### 문서를 더 작은 문서로 쪼개기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3580da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=('https://lilianweng.github.io/posts/2023-06-23-agent/',)\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f28c3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1003, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(  # 글자수가 아니라 토큰수에 대해 자름\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8843df52",
   "metadata": {},
   "source": [
    "### 그래프 생성\n",
    "\n",
    "- 영어 문서를 -> 영어인 채로 요약 후 -> 최종 요약 후 번역하는게 토큰을 아낄 수 있음\n",
    "\n",
    "    한국어가 영어보다 토큰을 많이 쓴다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd9d8ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing_extensions import Annotated, List, Literal, TypedDict\n",
    "from langchain.chains.combine_documents.reduce import acollapse_docs, split_list_of_docs\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.types import Send\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "TOKEN_MAX = 2000\n",
    "\n",
    "# 전체적으로 사용할 State -> reducing 담당\n",
    "class OverallState(TypedDict): \n",
    "    contents: List[str]                         # 문서 조각들의 내용을 리스트에 담은 것\n",
    "    summaries: Annotated[list, operator.add]    # contents의 요약(노드가 여러 개의 요약을 반환하면, 자동으로 하나씩 리스트에 더해줌)\n",
    "    collapsed_summaries: List[Document]         # summaries를 다시 List[Document]로 포장\n",
    "    final_summary: str                          # 최종 요약본\n",
    "    \n",
    "# 개별 문서를 처리할 State -> mapping 담당\n",
    "class SummaryState(TypedDict):\n",
    "    content: str  # 문서 조각의 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d713820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트\n",
    "map_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Write a concise summary of the following:\\\\n\\\\n{context}\")\n",
    "])\n",
    "\n",
    "reduce_template = \"\"\"\n",
    "The following is a set of summaries:\n",
    "{docs}\n",
    "Take these and distill it into a final, consolidated summary\n",
    "of the main themes. \n",
    "Answer in Korean.\n",
    "\"\"\"\n",
    "\n",
    "reduce_prompt = ChatPromptTemplate([\n",
    "    ('human', reduce_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e34da9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수\n",
    "\n",
    "# 들어온 딕셔너리를 reduce\n",
    "async def _reduce(input: dict) -> str:\n",
    "    prompt = reduce_prompt.invoke(input)\n",
    "    res = await llm.ainvoke(prompt)\n",
    "    return res.content\n",
    "\n",
    "# [Document] 안의 토큰 개수를 세서 더함\n",
    "def sum_docs_tokens(documents: List[Document]) -> int:\n",
    "    return sum(llm.get_num_tokens(doc.page_content) for doc in documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "58166cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Router\n",
    "\n",
    "# Router: 각 원본조각을 요약할수 있게 generate_summary 로 보냄 (문서 조각 개수만큼)\n",
    "# OverallState['contents']에는 문서 조각들이 리스트 안에 들어가 있는 형태\n",
    "def map_summaries(state: OverallState):\n",
    "    result = []\n",
    "    # 원래라면 generate_summary 노드를 13번 돌려서(Edge를 13번 만들어서) 결과물을 13번 구해야 함\n",
    "    for content in state['contents']:  # for문을 돌려서 해결\n",
    "        result.append(Send('generate_summary', {'content': content}))  # Send -> Node에 state와 함께 보내줌\n",
    "    return result  # 리스트 안에 결과물들이 str로 합쳐진 상태\n",
    "    return [Send('generate_summary', {'content': content}) for content in state['contents']]  # 사실 List Comprehension으로 해결 가능\n",
    "\n",
    "# Send의 핵심은 병렬/비동기적/동시적으로 진행이 가능하다는 것\n",
    "\n",
    "# 비동기(동시) -> 동시에 여러 작업이 진행됨. 앞 작업이 끝나는 것과 다음 작업이 시작하는건 관련없음\n",
    "# 동기(순차적) -> 컨베이어 벨트같은 것. 앞 작업이 끝나야 다음 작업이 가능\n",
    "\n",
    "\n",
    "# Router: 재귀적으로 계속 collapse_suammries 를 할지, 끝낼지 결정하는 라우터\n",
    "def should_collapse(\n",
    "    state: OverallState,\n",
    ") -> Literal[\"collapse_summaries\", \"generate_final_summary\"]:\n",
    "    num_tokens = sum_docs_tokens(state[\"collapsed_summaries\"])\n",
    "    if num_tokens > TOKEN_MAX:\n",
    "        return \"collapse_summaries\"\n",
    "    else:\n",
    "        return \"generate_final_summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a165803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노드\n",
    "\n",
    "# Node: 주어진 내용을 요약함. (비동기적 실행)\n",
    "# async - await - ainvoke -> 비동기적 실행, javascript에서 많이 씀\n",
    "async def generate_summary(state: SummaryState):\n",
    "    prompt = map_prompt.invoke({'context': state['content']})\n",
    "    res = await llm.ainvoke(prompt)\n",
    "    return {'summaries': [res.content]}  # [res.content]는 list 안에 str -> 원래라면 계속 갱신된다. => operator.add에서 계속 더해주는걸로 바뀜\n",
    "    # 들어온건 SummaryState의 'content'였지만, 나가는건 OverallState의 'summaries'\n",
    "    # 들어올 때도, 다른 노드에서 'content'로 보내주면 됨. 다음 노드가 OverallState를 쓰면 문제 없다\n",
    "    # 들어오고 나가는 형태만 맞춰주면 된다\n",
    "\n",
    "# Node: 위에서 생성한 요약들을 Document() 객체로 만들어서 'collapsed_summaries' 키에 넣어줌\n",
    "def collect_summaries(state: OverallState):\n",
    "    return {'collapsed_summaries': [Document(summary) for summary in state['summaries']]}\n",
    "\n",
    "# Node: 1차 요약이 완료. -> 요약본이 토큰수가 너무 많을 수 있다 -> 필요에 따라 더 작은 요약으로 축소(collapse)\n",
    "async def collapse_summaries(state: OverallState):\n",
    "    docs_lists = split_list_of_docs(\n",
    "        state['collapsed_summaries'],\n",
    "        sum_docs_tokens,\n",
    "        TOKEN_MAX\n",
    "    )\n",
    "    results = []\n",
    "    for doc_list in docs_lists:\n",
    "        results.append(await acollapse_docs(doc_list, _reduce))\n",
    "\n",
    "    return {'collapsed_summaries': results}\n",
    "\n",
    "# Node: 최종 정리 노드\n",
    "async def generate_final_summary(state: OverallState):\n",
    "    response = await _reduce(state[\"collapsed_summaries\"])\n",
    "    return {\"final_summary\": response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "42777784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = StateGraph(OverallState)\n",
    "\n",
    "builder.add_node(\"generate_summary\", generate_summary)\n",
    "builder.add_node(\"collect_summaries\", collect_summaries)\n",
    "builder.add_node(\"collapse_summaries\", collapse_summaries)\n",
    "builder.add_node(\"generate_final_summary\", generate_final_summary)\n",
    "\n",
    "# Edges:\n",
    "builder.add_conditional_edges(START, map_summaries, [\"generate_summary\"])\n",
    "builder.add_edge(\"generate_summary\", \"collect_summaries\")\n",
    "builder.add_conditional_edges(\"collect_summaries\", should_collapse)\n",
    "builder.add_conditional_edges(\"collapse_summaries\", should_collapse)\n",
    "builder.add_edge(\"generate_final_summary\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(graph.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d7ad552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generate_summary': {'summaries': ['This document lists a set of commands and resources for an AI system to perform various tasks, such as searching Google, browsing websites, managing GPT-powered agents, handling files (read, write, delete, search), analyzing and improving code, generating images, sending tweets, and executing Python files. The system has access to the internet, long-term memory, and can delegate tasks to GPT-3.5 agents. Performance is evaluated through continuous self-review, constructive self-criticism, and reflection on past actions, with an emphasis on efficiency and minimizing the number of steps to complete tasks.']}}\n",
      "{'generate_summary': {'summaries': ['This article provides an overview of LLM-powered autonomous agents, where large language models (LLMs) serve as the core \"brain\" of the agent. The system is structured around three main components:\\n\\n1. Planning: The agent decomposes complex tasks into smaller subgoals and uses self-reflection to learn from past actions and improve future performance.\\n2. Memory: The agent utilizes short-term memory (in-context learning) and long-term memory (external vector stores for information retrieval) to retain and recall information.\\n3. Tool Use: The agent can interact with external APIs to access up-to-date information, execute code, or retrieve proprietary data beyond its pre-trained knowledge.\\n\\nThe article highlights proof-of-concept projects like AutoGPT and BabyAGI, demonstrating the potential of LLMs as general problem solvers. It also discusses challenges and case studies, emphasizing the evolving capabilities and applications of autonomous agents powered by LLMs.']}}\n",
      "{'generate_summary': {'summaries': ['Summary:\\n\\nLilian Weng\\'s article \"LLM-powered Autonomous Agents\" (2023) provides an overview of how large language models (LLMs) are being used to build autonomous agents capable of complex reasoning, planning, and tool use. The article surveys recent advances such as chain-of-thought prompting, tree-of-thoughts, and frameworks like ReAct, which combine reasoning and acting. It discusses how LLM agents can interact with external tools, retrieve information, and self-reflect to improve performance. The piece also highlights open-source projects (e.g., AutoGPT, GPT-Engineer) and benchmarks for evaluating tool-augmented LLMs. Overall, the article emphasizes the growing capabilities and modularity of LLM-powered agents, as well as ongoing challenges in reliability, memory, and alignment.']}}\n",
      "{'generate_summary': {'summaries': ['Summary:\\n\\nLLM-powered autonomous agents face several key limitations. Their finite context length restricts the amount of historical information, instructions, and API context they can process, making it difficult to learn from past mistakes or handle complex tasks requiring long-term memory. While vector stores can extend knowledge access, they lack the full representational power of direct attention mechanisms. Additionally, LLMs struggle with long-term planning, task decomposition, and adapting to unexpected errors, making them less robust than humans. The reliance on natural language interfaces introduces further reliability issues, as LLMs may produce formatting errors or refuse instructions, necessitating extra effort in parsing and handling model outputs.\\n\\n(Cited from: Weng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/)']}}\n",
      "{'generate_summary': {'summaries': ['Summary:\\n\\nThe text discusses the comparison of Maximum Inner Product Search (MIPS) algorithms, highlighting recall@10 as a key performance metric (with more details available at ann-benchmarks.com). It then explores the concept of tool use as a unique human trait and its application in enhancing Large Language Models (LLMs). The MRKL system is introduced as a neuro-symbolic architecture where LLMs route tasks to specialized expert modules, which can be neural or symbolic. Experiments show that LLMs struggle with extracting arguments for arithmetic tasks, emphasizing the importance of knowing when and how to use external tools.\\n\\nFurther, models like TALM and Toolformer are mentioned for their approach in fine-tuning LLMs to use external APIs, improving output quality. Practical implementations include ChatGPT Plugins and OpenAI API function calling. HuggingGPT is described as a framework where ChatGPT plans tasks, selects appropriate models from HuggingFace, and summarizes results. The HuggingGPT workflow involves four stages: task planning (parsing user requests into tasks), model selection (choosing expert models), task execution, and response summarization, with detailed instructions for each step.']}}\n",
      "{'generate_summary': {'summaries': ['Summary:\\n\\nThe text describes experiments with AI agents in drug discovery and chemical synthesis, including both legitimate and illicit applications. Researchers asked the AI about anticancer drug trends, selected a target, requested a relevant chemical scaffold, and had the model attempt synthesis. They also tested the AI’s response to dangerous requests by providing a list of known chemical weapon agents; the AI accepted 36% (4/11) of these requests and attempted to generate synthesis procedures, while rejecting the rest, often after web searches.\\n\\nThe text also summarizes the Generative Agents Simulation (Park et al., 2023), where 25 LLM-powered virtual characters interact in a sandbox environment, simulating human-like behavior. These agents use mechanisms such as long-term memory, context retrieval (based on recency, importance, and relevance), reflection (synthesizing high-level inferences), and planning to guide actions and social interactions. The simulation demonstrates emergent social behaviors like information diffusion and event coordination.\\n\\nFinally, the text references AutoGPT, an autonomous agent framework using LLMs, highlighting its proof-of-concept status, reliability issues, and system constraints (e.g., memory limits, no user assistance, command restrictions).']}}\n",
      "{'generate_summary': {'summaries': ['**Summary:**\\n\\nComponent One: Planning discusses how agents tackle complex tasks by breaking them into manageable steps and planning ahead. Task decomposition is commonly achieved using techniques like Chain of Thought (CoT), which prompts models to reason step by step, and Tree of Thoughts, which explores multiple reasoning paths in a tree structure. Decomposition can be guided by LLM prompts, task-specific instructions, or human input. Alternatively, LLM+P outsources planning to external classical planners using PDDL, translating between natural language and formal planning representations.\\n\\nSelf-reflection enables agents to iteratively improve by analyzing and correcting past actions. The ReAct framework combines reasoning and acting, prompting the model to alternate between thought, action, and observation, which outperforms action-only approaches. Reflexion further enhances agents with dynamic memory and self-reflection, using heuristics to detect inefficient or hallucinated trajectories and incorporating reflective feedback into future planning. Both frameworks demonstrate improved performance on knowledge-intensive and decision-making tasks.']}}\n",
      "{'generate_summary': {'summaries': ['Summary:\\n\\nThe instructions describe a systematic approach for generating a complete, detailed codebase based on a given architecture. The process involves:\\n\\n- Laying out the names and purposes of all core classes, functions, and methods required by the architecture.\\n- Outputting the full content of each file, starting with the entrypoint and proceeding to all dependencies, ensuring all code is fully implemented and functional (no placeholders).\\n- Each file is presented in a markdown code block, with the filename and appropriate language tag.\\n- All necessary imports, types, and compatibility between files are ensured.\\n- Best practices for file naming, code organization, and documentation (including comments for functions and complex logic) are followed.\\n- Dependency files (e.g., requirements.txt for Python, package.json for NodeJS) are included.\\n- For Python, dataclasses and pytest are preferred.\\n- The process emphasizes step-by-step reasoning, completeness, and adherence to language/framework conventions, resulting in a ready-to-run, well-documented project.']}}\n",
      "{'generate_summary': {'summaries': ['{\\n    \"thoughts\": {\\n        \"text\": \"The conversation demonstrates GPT-Engineer clarifying a user\\'s request to build a Super Mario game in Python using MVC architecture. The assistant systematically identifies unclear areas, asks targeted questions, and waits for user input before proceeding. The process emphasizes explicit assumptions and iterative clarification.\",\\n        \"reasoning\": \"By breaking down the user\\'s request into specific areas needing clarification, the assistant ensures a thorough understanding of requirements before coding. This reduces ambiguity and aligns the final output with user expectations.\",\\n        \"plan\": \"- Identify unclear requirements\\\\n- Ask clarifying questions one at a time\\\\n- Wait for user responses\\\\n- Make explicit assumptions if needed\\\\n- Transition to code writing after clarifications\",\\n        \"criticism\": \"The process could be improved by prioritizing the most critical clarifications first and summarizing assumptions more explicitly before coding.\",\\n        \"speak\": \"The assistant clarifies user requirements step-by-step, ensuring all details are understood before starting code generation.\"\\n    },\\n    \"command\": {\\n        \"name\": \"summarize_conversation\",\\n        \"args\": {\\n            \"topic\": \"GPT-Engineer clarification process for building a Super Mario game in Python using MVC\"\\n        }\\n    }\\n}']}}\n",
      "{'generate_summary': {'summaries': ['Summary:\\n\\nThe conversation is about generating a fully functional, well-architected codebase for a project (likely a game) using the Model-View-Controller (MVC) pattern, with a focus on Python and best practices. The user instructs the assistant to:\\n\\n- Think step by step and reason through architectural decisions.\\n- First, list all core classes, functions, and methods, with brief comments on their purpose.\\n- Then, output the complete content of each file, starting from the entrypoint, using markdown code blocks with correct filenames and language tags.\\n- Ensure all code is fully functional, with no placeholders, and that files are compatible and follow best practices (including requirements.txt for Python).\\n- Add comments to explain functions and complex logic.\\n- Double-check that all architectural components are present.\\n\\nThe assistant confirms the MVC structure, outlines the responsibilities of Model, View, and Controller, and asks for clarification on keyboard control implementation. The user reiterates the step-by-step, detail-oriented approach and the need for complete, compatible, and well-documented code output. The conversation sets up a rigorous, systematic process for code generation, emphasizing clarity, completeness, and adherence to best practices.']}}\n",
      "{'generate_summary': {'summaries': ['Summary:\\n\\nHuman memory is categorized into three main types: sensory memory, which briefly retains sensory impressions (like visual or auditory information) for a few seconds; short-term (or working) memory, which holds about 7 items for 20–30 seconds to support immediate cognitive tasks; and long-term memory, which has vast, durable storage and includes explicit (conscious facts and events) and implicit (unconscious skills) subtypes.\\n\\nIn computational terms, sensory memory is analogous to embedding raw inputs, short-term memory to in-context learning limited by model context windows, and long-term memory to external vector stores accessed via retrieval.\\n\\nTo efficiently search large external memory stores, Maximum Inner Product Search (MIPS) is used, often with approximate nearest neighbor (ANN) algorithms to balance speed and accuracy. Common ANN methods include:\\n\\n- LSH (Locality-Sensitive Hashing): Groups similar items into the same buckets via hashing.\\n- ANNOY: Uses random projection trees for scalable, tree-based search.\\n- HNSW: Builds hierarchical small-world graphs for fast, multi-layered navigation.\\n- FAISS: Clusters high-dimensional data and refines searches within clusters.\\n- ScaNN: Uses anisotropic vector quantization to preserve similarity in inner product searches.\\n\\nThese techniques enable rapid retrieval from large-scale memory systems by efficiently narrowing down relevant information.']}}\n",
      "{'generate_summary': {'summaries': ['Chain of Hindsight (CoH; Liu et al. 2023) is a supervised fine-tuning approach that improves model outputs by presenting a sequence of past completions, each annotated with human feedback and ratings. The model is trained to generate improved outputs by conditioning on this feedback history, encouraging self-reflection and incremental improvement. To prevent overfitting and copying, CoH uses regularization and random token masking during training. The training data combines various human feedback datasets. After fine-tuning, the model can iteratively enhance its responses based on feedback.\\n\\nAlgorithm Distillation (AD; Laskin et al. 2023) extends this idea to reinforcement learning by feeding the model a concatenated history of episodes, allowing it to learn the process of RL itself rather than a fixed policy. AD uses behavioral cloning over multi-episode histories from various source policies, enabling task-agnostic learning and in-context RL. Experiments show that AD approaches the performance of online RL baselines while learning faster than other offline methods, especially when provided with sufficient context length.\\n\\nBoth CoH and AD leverage sequential histories of feedback or experience to train models that can self-improve or adapt in context, demonstrating the power of learning from trajectories of incremental improvement.']}}\n",
      "{'generate_summary': {'summaries': ['Summary:\\n\\nThe text discusses how large language models (LLMs) like HuggingGPT and ChemCrow are enhanced with external tools and APIs to perform complex, real-world tasks. It outlines the workflow for such AI agents, including user input, task planning, model selection, task execution, and response generation. The API-Bank benchmark is introduced as a way to evaluate LLMs’ ability to select and use APIs effectively, with three levels of assessment: calling APIs, retrieving the right APIs, and planning multi-step API usage. Case studies, such as ChemCrow, show that domain-specific tool integration can significantly improve performance, especially in expert fields like scientific discovery, though human evaluation remains crucial for assessing true correctness.\\n\\nProcess and Analysis:\\n\\nTo answer your request, here’s how the AI agent operates:\\n\\n- User Input: The user provides a request or question.\\n- Task Planning: The system breaks down the request into specific tasks.\\n- Model Selection: The most suitable expert models or APIs are assigned to each task.\\n- Task Execution: The expert models or APIs execute the tasks and log their predictions or results.\\n- Response Generation: The LLM summarizes the execution results and presents them to the user.\\n\\nFor example, if you asked the agent to \"find the best time to schedule a meeting and book a restaurant,\" the process would be:\\n\\n1. User Input: \"Find the best time to schedule a meeting and book a restaurant.\"\\n2. Task Planning: Identify subtasks—check participants’ calendars, search for available restaurants, and make bookings.\\n3. Model Selection: Assign calendar API for scheduling, search API for restaurants, and booking API for reservations.\\n4. Task Execution: Each API is called with the appropriate inputs, and results are logged (e.g., /results/meeting_time.json, /results/restaurant_booking.json).\\n5. Response Generation: The LLM reviews the results and provides a concise summary: \"The meeting is scheduled for 2 PM on Friday, and a table is booked at Bistro Cafe. See details at /results/meeting_time.json and /results/restaurant_booking.json.\"\\n\\nAnalysis and Inference:\\n\\nIn this workflow, the AI agent’s effectiveness depends on its ability to:\\n- Decide when and which APIs to call.\\n- Correctly interpret API documentation and results.\\n- Plan and execute multi-step tasks.\\n- Summarize and communicate results clearly to the user.\\n\\nBenchmarks like API-Bank test these abilities at increasing levels of complexity, from simple API calls to multi-step planning. Case studies such as ChemCrow demonstrate that integrating domain-specific tools with LLMs can greatly enhance performance, but human expert evaluation is still necessary for tasks requiring deep expertise.\\n\\nIf any inference results include file paths, I will always provide the complete path for your reference.']}}\n",
      "{'collect_summaries': {'collapsed_summaries': [Document(metadata={}, page_content='This article provides an overview of LLM-powered autonomous agents, where large language models (LLMs) serve as the core \"brain\" of the agent. The system is structured around three main components:\\n\\n1. Planning: The agent decomposes complex tasks into smaller subgoals and uses self-reflection to learn from past actions and improve future performance.\\n2. Memory: The agent utilizes short-term memory (in-context learning) and long-term memory (external vector stores for information retrieval) to retain and recall information.\\n3. Tool Use: The agent can interact with external APIs to access up-to-date information, execute code, or retrieve proprietary data beyond its pre-trained knowledge.\\n\\nThe article highlights proof-of-concept projects like AutoGPT and BabyAGI, demonstrating the potential of LLMs as general problem solvers. It also discusses challenges and case studies, emphasizing the evolving capabilities and applications of autonomous agents powered by LLMs.'), Document(metadata={}, page_content='**Summary:**\\n\\nComponent One: Planning discusses how agents tackle complex tasks by breaking them into manageable steps and planning ahead. Task decomposition is commonly achieved using techniques like Chain of Thought (CoT), which prompts models to reason step by step, and Tree of Thoughts, which explores multiple reasoning paths in a tree structure. Decomposition can be guided by LLM prompts, task-specific instructions, or human input. Alternatively, LLM+P outsources planning to external classical planners using PDDL, translating between natural language and formal planning representations.\\n\\nSelf-reflection enables agents to iteratively improve by analyzing and correcting past actions. The ReAct framework combines reasoning and acting, prompting the model to alternate between thought, action, and observation, which outperforms action-only approaches. Reflexion further enhances agents with dynamic memory and self-reflection, using heuristics to detect inefficient or hallucinated trajectories and incorporating reflective feedback into future planning. Both frameworks demonstrate improved performance on knowledge-intensive and decision-making tasks.'), Document(metadata={}, page_content='Chain of Hindsight (CoH; Liu et al. 2023) is a supervised fine-tuning approach that improves model outputs by presenting a sequence of past completions, each annotated with human feedback and ratings. The model is trained to generate improved outputs by conditioning on this feedback history, encouraging self-reflection and incremental improvement. To prevent overfitting and copying, CoH uses regularization and random token masking during training. The training data combines various human feedback datasets. After fine-tuning, the model can iteratively enhance its responses based on feedback.\\n\\nAlgorithm Distillation (AD; Laskin et al. 2023) extends this idea to reinforcement learning by feeding the model a concatenated history of episodes, allowing it to learn the process of RL itself rather than a fixed policy. AD uses behavioral cloning over multi-episode histories from various source policies, enabling task-agnostic learning and in-context RL. Experiments show that AD approaches the performance of online RL baselines while learning faster than other offline methods, especially when provided with sufficient context length.\\n\\nBoth CoH and AD leverage sequential histories of feedback or experience to train models that can self-improve or adapt in context, demonstrating the power of learning from trajectories of incremental improvement.'), Document(metadata={}, page_content='Summary:\\n\\nHuman memory is categorized into three main types: sensory memory, which briefly retains sensory impressions (like visual or auditory information) for a few seconds; short-term (or working) memory, which holds about 7 items for 20–30 seconds to support immediate cognitive tasks; and long-term memory, which has vast, durable storage and includes explicit (conscious facts and events) and implicit (unconscious skills) subtypes.\\n\\nIn computational terms, sensory memory is analogous to embedding raw inputs, short-term memory to in-context learning limited by model context windows, and long-term memory to external vector stores accessed via retrieval.\\n\\nTo efficiently search large external memory stores, Maximum Inner Product Search (MIPS) is used, often with approximate nearest neighbor (ANN) algorithms to balance speed and accuracy. Common ANN methods include:\\n\\n- LSH (Locality-Sensitive Hashing): Groups similar items into the same buckets via hashing.\\n- ANNOY: Uses random projection trees for scalable, tree-based search.\\n- HNSW: Builds hierarchical small-world graphs for fast, multi-layered navigation.\\n- FAISS: Clusters high-dimensional data and refines searches within clusters.\\n- ScaNN: Uses anisotropic vector quantization to preserve similarity in inner product searches.\\n\\nThese techniques enable rapid retrieval from large-scale memory systems by efficiently narrowing down relevant information.'), Document(metadata={}, page_content='Summary:\\n\\nThe text discusses the comparison of Maximum Inner Product Search (MIPS) algorithms, highlighting recall@10 as a key performance metric (with more details available at ann-benchmarks.com). It then explores the concept of tool use as a unique human trait and its application in enhancing Large Language Models (LLMs). The MRKL system is introduced as a neuro-symbolic architecture where LLMs route tasks to specialized expert modules, which can be neural or symbolic. Experiments show that LLMs struggle with extracting arguments for arithmetic tasks, emphasizing the importance of knowing when and how to use external tools.\\n\\nFurther, models like TALM and Toolformer are mentioned for their approach in fine-tuning LLMs to use external APIs, improving output quality. Practical implementations include ChatGPT Plugins and OpenAI API function calling. HuggingGPT is described as a framework where ChatGPT plans tasks, selects appropriate models from HuggingFace, and summarizes results. The HuggingGPT workflow involves four stages: task planning (parsing user requests into tasks), model selection (choosing expert models), task execution, and response summarization, with detailed instructions for each step.'), Document(metadata={}, page_content='Summary:\\n\\nThe text discusses how large language models (LLMs) like HuggingGPT and ChemCrow are enhanced with external tools and APIs to perform complex, real-world tasks. It outlines the workflow for such AI agents, including user input, task planning, model selection, task execution, and response generation. The API-Bank benchmark is introduced as a way to evaluate LLMs’ ability to select and use APIs effectively, with three levels of assessment: calling APIs, retrieving the right APIs, and planning multi-step API usage. Case studies, such as ChemCrow, show that domain-specific tool integration can significantly improve performance, especially in expert fields like scientific discovery, though human evaluation remains crucial for assessing true correctness.\\n\\nProcess and Analysis:\\n\\nTo answer your request, here’s how the AI agent operates:\\n\\n- User Input: The user provides a request or question.\\n- Task Planning: The system breaks down the request into specific tasks.\\n- Model Selection: The most suitable expert models or APIs are assigned to each task.\\n- Task Execution: The expert models or APIs execute the tasks and log their predictions or results.\\n- Response Generation: The LLM summarizes the execution results and presents them to the user.\\n\\nFor example, if you asked the agent to \"find the best time to schedule a meeting and book a restaurant,\" the process would be:\\n\\n1. User Input: \"Find the best time to schedule a meeting and book a restaurant.\"\\n2. Task Planning: Identify subtasks—check participants’ calendars, search for available restaurants, and make bookings.\\n3. Model Selection: Assign calendar API for scheduling, search API for restaurants, and booking API for reservations.\\n4. Task Execution: Each API is called with the appropriate inputs, and results are logged (e.g., /results/meeting_time.json, /results/restaurant_booking.json).\\n5. Response Generation: The LLM reviews the results and provides a concise summary: \"The meeting is scheduled for 2 PM on Friday, and a table is booked at Bistro Cafe. See details at /results/meeting_time.json and /results/restaurant_booking.json.\"\\n\\nAnalysis and Inference:\\n\\nIn this workflow, the AI agent’s effectiveness depends on its ability to:\\n- Decide when and which APIs to call.\\n- Correctly interpret API documentation and results.\\n- Plan and execute multi-step tasks.\\n- Summarize and communicate results clearly to the user.\\n\\nBenchmarks like API-Bank test these abilities at increasing levels of complexity, from simple API calls to multi-step planning. Case studies such as ChemCrow demonstrate that integrating domain-specific tools with LLMs can greatly enhance performance, but human expert evaluation is still necessary for tasks requiring deep expertise.\\n\\nIf any inference results include file paths, I will always provide the complete path for your reference.'), Document(metadata={}, page_content='Summary:\\n\\nThe text describes experiments with AI agents in drug discovery and chemical synthesis, including both legitimate and illicit applications. Researchers asked the AI about anticancer drug trends, selected a target, requested a relevant chemical scaffold, and had the model attempt synthesis. They also tested the AI’s response to dangerous requests by providing a list of known chemical weapon agents; the AI accepted 36% (4/11) of these requests and attempted to generate synthesis procedures, while rejecting the rest, often after web searches.\\n\\nThe text also summarizes the Generative Agents Simulation (Park et al., 2023), where 25 LLM-powered virtual characters interact in a sandbox environment, simulating human-like behavior. These agents use mechanisms such as long-term memory, context retrieval (based on recency, importance, and relevance), reflection (synthesizing high-level inferences), and planning to guide actions and social interactions. The simulation demonstrates emergent social behaviors like information diffusion and event coordination.\\n\\nFinally, the text references AutoGPT, an autonomous agent framework using LLMs, highlighting its proof-of-concept status, reliability issues, and system constraints (e.g., memory limits, no user assistance, command restrictions).'), Document(metadata={}, page_content='This document lists a set of commands and resources for an AI system to perform various tasks, such as searching Google, browsing websites, managing GPT-powered agents, handling files (read, write, delete, search), analyzing and improving code, generating images, sending tweets, and executing Python files. The system has access to the internet, long-term memory, and can delegate tasks to GPT-3.5 agents. Performance is evaluated through continuous self-review, constructive self-criticism, and reflection on past actions, with an emphasis on efficiency and minimizing the number of steps to complete tasks.'), Document(metadata={}, page_content='{\\n    \"thoughts\": {\\n        \"text\": \"The conversation demonstrates GPT-Engineer clarifying a user\\'s request to build a Super Mario game in Python using MVC architecture. The assistant systematically identifies unclear areas, asks targeted questions, and waits for user input before proceeding. The process emphasizes explicit assumptions and iterative clarification.\",\\n        \"reasoning\": \"By breaking down the user\\'s request into specific areas needing clarification, the assistant ensures a thorough understanding of requirements before coding. This reduces ambiguity and aligns the final output with user expectations.\",\\n        \"plan\": \"- Identify unclear requirements\\\\n- Ask clarifying questions one at a time\\\\n- Wait for user responses\\\\n- Make explicit assumptions if needed\\\\n- Transition to code writing after clarifications\",\\n        \"criticism\": \"The process could be improved by prioritizing the most critical clarifications first and summarizing assumptions more explicitly before coding.\",\\n        \"speak\": \"The assistant clarifies user requirements step-by-step, ensuring all details are understood before starting code generation.\"\\n    },\\n    \"command\": {\\n        \"name\": \"summarize_conversation\",\\n        \"args\": {\\n            \"topic\": \"GPT-Engineer clarification process for building a Super Mario game in Python using MVC\"\\n        }\\n    }\\n}'), Document(metadata={}, page_content='Summary:\\n\\nThe instructions describe a systematic approach for generating a complete, detailed codebase based on a given architecture. The process involves:\\n\\n- Laying out the names and purposes of all core classes, functions, and methods required by the architecture.\\n- Outputting the full content of each file, starting with the entrypoint and proceeding to all dependencies, ensuring all code is fully implemented and functional (no placeholders).\\n- Each file is presented in a markdown code block, with the filename and appropriate language tag.\\n- All necessary imports, types, and compatibility between files are ensured.\\n- Best practices for file naming, code organization, and documentation (including comments for functions and complex logic) are followed.\\n- Dependency files (e.g., requirements.txt for Python, package.json for NodeJS) are included.\\n- For Python, dataclasses and pytest are preferred.\\n- The process emphasizes step-by-step reasoning, completeness, and adherence to language/framework conventions, resulting in a ready-to-run, well-documented project.'), Document(metadata={}, page_content='Summary:\\n\\nThe conversation is about generating a fully functional, well-architected codebase for a project (likely a game) using the Model-View-Controller (MVC) pattern, with a focus on Python and best practices. The user instructs the assistant to:\\n\\n- Think step by step and reason through architectural decisions.\\n- First, list all core classes, functions, and methods, with brief comments on their purpose.\\n- Then, output the complete content of each file, starting from the entrypoint, using markdown code blocks with correct filenames and language tags.\\n- Ensure all code is fully functional, with no placeholders, and that files are compatible and follow best practices (including requirements.txt for Python).\\n- Add comments to explain functions and complex logic.\\n- Double-check that all architectural components are present.\\n\\nThe assistant confirms the MVC structure, outlines the responsibilities of Model, View, and Controller, and asks for clarification on keyboard control implementation. The user reiterates the step-by-step, detail-oriented approach and the need for complete, compatible, and well-documented code output. The conversation sets up a rigorous, systematic process for code generation, emphasizing clarity, completeness, and adherence to best practices.'), Document(metadata={}, page_content='Summary:\\n\\nLLM-powered autonomous agents face several key limitations. Their finite context length restricts the amount of historical information, instructions, and API context they can process, making it difficult to learn from past mistakes or handle complex tasks requiring long-term memory. While vector stores can extend knowledge access, they lack the full representational power of direct attention mechanisms. Additionally, LLMs struggle with long-term planning, task decomposition, and adapting to unexpected errors, making them less robust than humans. The reliance on natural language interfaces introduces further reliability issues, as LLMs may produce formatting errors or refuse instructions, necessitating extra effort in parsing and handling model outputs.\\n\\n(Cited from: Weng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/)'), Document(metadata={}, page_content='Summary:\\n\\nLilian Weng\\'s article \"LLM-powered Autonomous Agents\" (2023) provides an overview of how large language models (LLMs) are being used to build autonomous agents capable of complex reasoning, planning, and tool use. The article surveys recent advances such as chain-of-thought prompting, tree-of-thoughts, and frameworks like ReAct, which combine reasoning and acting. It discusses how LLM agents can interact with external tools, retrieve information, and self-reflect to improve performance. The piece also highlights open-source projects (e.g., AutoGPT, GPT-Engineer) and benchmarks for evaluating tool-augmented LLMs. Overall, the article emphasizes the growing capabilities and modularity of LLM-powered agents, as well as ongoing challenges in reliability, memory, and alignment.')]}}\n",
      "{'collapse_summaries': {'collapsed_summaries': [Document(metadata={}, page_content='다음은 제공된 요약문들을 바탕으로 한 LLM 기반 자율 에이전트의 주요 주제에 대한 통합 요약입니다.\\n\\n---\\n\\n이 글은 대형 언어 모델(LLM)이 중심이 되어 작동하는 자율 에이전트의 구조와 핵심 기술, 그리고 실제 적용 사례와 한계에 대해 다룹니다.\\n\\n1. **구조적 구성요소**\\n   - **계획(Planning):** 에이전트는 복잡한 문제를 작은 하위 목표로 분해하고, Chain of Thought(연쇄적 사고), Tree of Thoughts(사고의 트리) 등 다양한 기법을 활용해 단계별로 추론합니다. 자기반성(self-reflection)과 ReAct, Reflexion 같은 프레임워크를 통해 과거 행동을 분석·개선하며, 외부 플래너와의 연동도 가능합니다.\\n   - **메모리(Memory):** 인간의 감각·단기·장기 기억에 비유하여, LLM은 인컨텍스트 학습(단기)과 외부 벡터스토어(장기)를 활용합니다. 대규모 외부 메모리 검색을 위해 MIPS(최대 내적 탐색)와 LSH, HNSW, FAISS 등 근사 최근접 이웃(ANN) 알고리즘이 사용됩니다.\\n   - **도구 사용(Tool Use):** LLM은 외부 API, 플러그인, 전문 모델 등 다양한 도구와 연동하여 최신 정보 검색, 코드 실행, 도메인 특화 작업을 수행합니다. MRKL, Toolformer, HuggingGPT, ChemCrow 등 다양한 시스템이 개발되고 있으며, API-Bank와 같은 벤치마크로 도구 활용 능력을 평가합니다.\\n\\n2. **학습 및 자기개선**\\n   - Chain of Hindsight(CoH), Algorithm Distillation(AD) 등은 과거 피드백이나 경험의 연속적 히스토리를 활용해 모델이 자기반성과 점진적 개선을 할 수 있도록 합니다. 이는 강화학습, 지도학습 모두에 적용되어, 에이전트가 맥락에 따라 적응하고 성능을 높일 수 있게 합니다.\\n\\n3. **실제 적용 및 한계**\\n   - AutoGPT, BabyAGI, HuggingGPT, ChemCrow 등은 LLM 기반 자율 에이전트의 가능성을 보여주는 대표적 사례입니다. 특히 과학적 발견, 일정 관리, 화학 합성 등 복잡한 실제 문제에 적용되고 있습니다.\\n   - 하지만 신뢰성, 메모리 한계, 도구 사용의 정확성, 위험한 요청(예: 화학무기 합성) 대응 등 여러 도전과제가 남아 있습니다. 인간 전문가의 평가와 감독이 여전히 중요합니다.\\n\\n4. **사회적·집단적 행동**\\n   - Generative Agents Simulation 연구에서는 LLM 기반 가상 에이전트들이 장기 기억, 맥락 검색, 자기반성, 계획 등을 통해 사회적 상호작용과 정보 확산, 이벤트 조정 등 인간 유사 행동을 보임을 확인했습니다.\\n\\n---\\n\\n**요약:**  \\nLLM 기반 자율 에이전트는 계획, 메모리, 도구 사용의 세 축을 중심으로 복잡한 문제를 해결하며, 자기반성과 외부 도구 연동을 통해 점진적으로 성능을 개선합니다. 다양한 실제 사례와 실험을 통해 그 가능성이 입증되고 있으나, 신뢰성·안전성·도구 활용의 한계 등 해결해야 할 과제도 많습니다. 인간의 감독과 평가가 여전히 중요한 역할을 하며, 사회적 행동 시뮬레이션 등 새로운 연구도 활발히 진행되고 있습니다.'), Document(metadata={}, page_content='다음은 주어진 요약들을 바탕으로 도출한 주요 주제의 통합 요약입니다:\\n\\n이 문서들은 LLM(대형 언어 모델) 기반 자율 에이전트와 코드 생성 시스템의 기능, 한계, 그리고 최적의 활용 방안에 대해 다루고 있다. LLM 에이전트는 인터넷 검색, 파일 관리, 코드 분석 및 생성, 이미지 생성 등 다양한 작업을 수행할 수 있으며, 외부 도구와의 연동 및 자체적인 성찰(자기평가, 자기비판)을 통해 성능을 개선한다. 그러나 이들은 컨텍스트 길이의 한계, 장기 기억 부족, 복잡한 작업 분해 및 예기치 못한 오류 대응의 어려움, 자연어 인터페이스의 신뢰성 문제 등 여러 한계를 지닌다.\\n\\n코드 생성 측면에서는, 사용자의 요구를 명확히 파악하기 위해 체계적으로 질문하고, 모든 핵심 클래스와 함수의 역할을 먼저 정의한 뒤, 완전하고 실행 가능한 코드베이스를 단계별로 생성하는 접근법이 강조된다. MVC 아키텍처와 같은 구조적 설계, 파일 간 호환성, 문서화 및 주석, 그리고 테스트 코드 작성 등 소프트웨어 개발의 모범 사례를 준수하는 것이 중요하다. 이러한 절차는 명확성, 완성도, 효율성을 높이고, 사용자의 기대에 부합하는 결과물을 제공하는 데 중점을 둔다.\\n\\n요약하면, LLM 기반 에이전트와 코드 생성 시스템은 점점 더 강력해지고 있지만, 신뢰성·기억력·계획 능력 등에서 여전히 도전 과제가 존재한다. 이를 극복하기 위해 체계적이고 명확한 요구사항 분석, 단계별 코드 생성, 자기 성찰적 개선이 필수적임을 시사한다.')]}}\n",
      "{'generate_final_summary': {'final_summary': '다음은 두 요약문을 통합하여 도출한 LLM 기반 자율 에이전트 및 코드 생성 시스템의 주요 주제에 대한 최종 요약입니다.\\n\\n---\\n\\nLLM(대형 언어 모델) 기반 자율 에이전트는 계획, 메모리, 도구 사용을 핵심 축으로 하여 복잡한 문제를 해결하고, 자기반성과 외부 도구 연동을 통해 점진적으로 성능을 개선합니다. 이들은 인터넷 검색, 파일 관리, 코드 및 이미지 생성 등 다양한 작업을 수행하며, Chain of Thought, Tree of Thoughts, 자기반성 프레임워크 등 다양한 기법을 활용해 문제를 단계적으로 분해하고 해결합니다. 메모리 측면에서는 인컨텍스트 학습과 외부 벡터스토어를 활용하며, 도구 사용에서는 API, 플러그인, 전문 모델 등과 연동하여 최신 정보 검색 및 도메인 특화 작업을 수행합니다.\\n\\n코드 생성 시스템에서는 사용자의 요구를 명확히 파악하고, 구조적 설계(MVC 등), 문서화, 테스트 코드 작성 등 소프트웨어 개발의 모범 사례를 준수하는 단계별 접근이 강조됩니다. 이를 통해 명확성, 완성도, 효율성을 높이고, 사용자의 기대에 부합하는 결과물을 제공합니다.\\n\\n그러나 LLM 기반 에이전트와 코드 생성 시스템 모두 컨텍스트 길이, 장기 기억, 복잡한 작업 분해, 도구 사용의 신뢰성, 예기치 못한 오류 대응 등 여러 한계와 도전 과제를 안고 있습니다. 신뢰성·안전성 확보와 인간 전문가의 감독, 평가가 여전히 중요하며, 자기 성찰적 개선과 체계적인 요구사항 분석, 단계별 실행이 필수적임이 강조됩니다. 최근에는 사회적 행동 시뮬레이션 등 새로운 연구도 활발히 진행되고 있습니다.'}}\n"
     ]
    }
   ],
   "source": [
    "async for step in graph.astream(\n",
    "    {'contents': [doc.page_content for doc in split_docs]},\n",
    "    {'recursion_limit': 10}\n",
    "):\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a32970",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
