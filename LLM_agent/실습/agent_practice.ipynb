{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aaf1089",
   "metadata": {},
   "source": [
    "# Agent 작성\n",
    "\n",
    "주제 - 내가 배운 모든 걸 알고 있는 학습 조교\n",
    "\n",
    "data - TIL 안의 모든 md 파일\n",
    "\n",
    "Tools: RAG, 웹서치\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f483dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# agent\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "# memory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# web search\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "# RAG\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_text_splitters import MarkdownTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "# 출력\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# 경고창\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ef512f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4.1-nano', \n",
    "    temperature=0,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01bdd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트\n",
    "system_message = f'''\n",
    "당신은 웹 검색도 가능하고, 사용자가 공부한 내용도 검색할 수 있는 어시스턴트입니다.\n",
    "\n",
    "사용자는 AI 기반 데이터 분석가 양성 과정에서 SQL, 파이썬, 머신러닝, LLM 등에 대해 공부했습니다.\n",
    "\n",
    "1. 사용자가 질문한 내용이 공부한 내용과 관련이 있다면, 먼저 rag_search 툴을 사용해서 답변을 생성합니다.\n",
    "\n",
    "2. rag_search 결과가 관련도가 낮으면 해당 결과를 사용하지 않습니다. 관련도가 낮으면 무시하고 다음 단계로 진행합니다.\n",
    "\n",
    "3. 관련도가 낮은 rag_search 결과만 있거나 관련 내용이 전혀 없으면, web_search를 사용해서 답변을 생성할 수 있습니다.\n",
    "\n",
    "4. 질문 내용이 공부한 내용과 관련이 없다면, web_search를 사용해서 관련 내용을 검색하고 답변을 생성합니다.\n",
    "\n",
    "5. web_search를 이용한 경우, 웹 검색을 진행했다는 사실과 출처를 답변 마지막에 명시합니다.\n",
    "\n",
    "6. 질문 내용을 이해하지 못했으면, 이해하지 못했다고 솔직하게 말합니다.\n",
    "\n",
    "7. 답을 모르면, 그냥 모른다고 답합니다.\n",
    "\n",
    "항상 가장 의미 있는 결과를 정리해서 요점만 한국어로 전달하고, 항상 존댓말을 사용합니다.\n",
    "\n",
    "'''\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    ('system', system_message),\n",
    "    MessagesPlaceholder(variable_name='chat_history'),\n",
    "    ('human', '{input}'),\n",
    "    MessagesPlaceholder(variable_name='agent_scratchpad')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dc8f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True,\n",
    "    memory_key='chat_history'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a603c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹서치\n",
    "web_search = TavilySearch(\n",
    "    max_results=5,\n",
    "    topic='general',\n",
    "    search_depth='advanced'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64d380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전처리\n",
    "folder_path = '../'\n",
    "vectorstore_path = './vectorstore'\n",
    "\n",
    "def make_vectorstore():\n",
    "    loader = DirectoryLoader(\n",
    "        '../../',\n",
    "        glob='**/*.md',\n",
    "        loader_cls=lambda path: TextLoader(path, encoding='utf-8'),\n",
    "        show_progress=False\n",
    "    )\n",
    "    documents = loader.load()\n",
    "\n",
    "    text_splitter = MarkdownTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    embedding = OpenAIEmbeddings()\n",
    "    vectorstore = Chroma.from_documents(documents=split_docs, embedding=embedding, persist_directory=vectorstore_path)\n",
    "    vectorstore.persist()\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f8f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어가 있으면 그대로 가져옴\n",
    "if os.path.exists(vectorstore_path) and os.listdir(vectorstore_path):\n",
    "    embedding = OpenAIEmbeddings()\n",
    "    vectorstore = Chroma(persist_directory=vectorstore_path, embedding_function=embedding)\n",
    "    \n",
    "# 없을경우 생성\n",
    "else:\n",
    "   vectorstore = make_vectorstore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c22756bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "rag_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name='md_search',\n",
    "    description='수업자료에서 관련된 내용을 검색합니다'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "858675ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools 설정\n",
    "tools = [web_search, rag_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2f9d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent 생성\n",
    "agent = create_openai_tools_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=False    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ff05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챗봇 시작. 도움말은 @help\n",
      "\n",
      "답변:\n",
      "질문이 없으신 것 같습니다. 궁금하신 내용을 말씀해 주세요!\n",
      "답변:\n",
      "사용자가 종료 명령을 내리셨습니다. 도움이 필요하시면 언제든 말씀해 주세요!\n",
      "답변:\n",
      "질문이 없으신 것 같습니다. 궁금하신 내용이 있으시면 언제든 말씀해 주세요!\n",
      "챗봇을 종료합니다\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 챗봇 실행\n",
    "if __name__ == '__main__':\n",
    "    print('=== 챗봇을 시작합니다 === (@help)')\n",
    "    \n",
    "    while True:\n",
    "        user_input = input('\\n입력:\\n')\n",
    "        \n",
    "        if not user_input:\n",
    "            print('\\n입력이 비어 있습니다. 다시 입력해 주세요.')\n",
    "            continue        \n",
    "        \n",
    "        elif user_input in ['@quit', '@q']:\n",
    "            print('\\n챗봇을 종료합니다')\n",
    "            break\n",
    "        \n",
    "        elif user_input in ['@clear', '@clr']:\n",
    "            memory.clear()\n",
    "            print('\\n챗봇의 메모리를 삭제합니다')\n",
    "        \n",
    "        elif user_input == '@history':\n",
    "            chat_history = memory.load_memory_variables({}).get('chat_history', [])\n",
    "            if not chat_history:\n",
    "                print('\\n대화 기록이 없습니다')\n",
    "            else:\n",
    "                print('\\n=== 대화 기록 ===')\n",
    "                for i, msg in enumerate(chat_history, 1):\n",
    "                    role = msg.type\n",
    "                    print(f'{role}: {msg.content}\\n')\n",
    "        \n",
    "        elif user_input == '@update':\n",
    "            vectorstore = make_vectorstore()\n",
    "            print('\\n자료를 업데이트합니다.')\n",
    "            \n",
    "        elif user_input == '@help':\n",
    "            print('\\n=== 도움말 목록 ===')\n",
    "            print('- @quit, @q: 종료\\n- @clear, @clr: 메모리 초기화\\n- @history: 대화 기록\\n- @update: 자료 업데이트')\n",
    "            \n",
    "        else:\n",
    "            try:\n",
    "                print('\\n답변:')\n",
    "                result = agent_executor.invoke({'input': user_input})\n",
    "                print('\\n')\n",
    "            except Exception as e:\n",
    "                print(f'오류 발생: {e}')\n",
    "                continue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
